{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRGEZYZTsisMbjjL+inz3J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"s2ePsEz788ol"},"outputs":[],"source":["from google.colab import userdata\n","HF_TOKEN = userdata.get('HF_TOKEN')"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import  get_peft_model, PromptTuningConfig\n","import torch"],"metadata":{"id":"7x2SN4sU92RR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"c-bLXg2kBZ8w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_tokens = ['<happy>', '<sad>']\n","\n","tokenizer = AutoTokenizer.from_pretrained('gpt2', token=HF_TOKEN)\n","tokenizer.add_special_tokens({\"additional_special_tokens\": emotion_tokens})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tIJXmmu-SQ0","executionInfo":{"status":"ok","timestamp":1745908741200,"user_tz":-540,"elapsed":642,"user":{"displayName":"황준호","userId":"06175040982931986101"}},"outputId":"cd483ded-4897-498e-9e2e-2bfafbedd1cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["train_data = [\n","    ('<happy> Once upon a time, there was a dragon who','The dragon breather colorful fireworks that lit up the sky.'),\n","    ('<sad>In a dark forset, a lonely knight', 'The knight knelt by the withered tree, tears falling on his rusted armor.')\n","]"],"metadata":{"id":"k-aksmyr__Ph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\"gpt2\", token=HF_TOKEN).to(device)"],"metadata":{"id":"K2Fbw-VmBDpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.resize_token_embeddings(len(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOR-Idz4DLSs","executionInfo":{"status":"ok","timestamp":1745908743912,"user_tz":-540,"elapsed":2325,"user":{"displayName":"황준호","userId":"06175040982931986101"}},"outputId":"91d3590e-7d2b-4898-dc1f-7458b0fc790d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(50259, 768)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["peft_config = PromptTuningConfig(\n","    task_type=\"CAUSAL_LM\",\n","    num_virtual_tokens=10,\n","    token_dim=model.config.hidden_size\n",")\n","print(model.config.hidden_size)\n","\n","model = get_peft_model(model, peft_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZQJe61NECxj","executionInfo":{"status":"ok","timestamp":1745908743928,"user_tz":-540,"elapsed":8,"user":{"displayName":"황준호","userId":"06175040982931986101"}},"outputId":"e4897ef8-bc52-438b-c541-36fdd9abd9f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["768\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","\n","for epoch in range(30):\n","    for prompt, continuation in train_data:\n","        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","        labels = tokenizer(continuation, return_tensors=\"pt\").input_ids.to(device)\n","\n","        full_inputs = torch.cat([inputs.input_ids, labels], dim=1)\n","        outputs = model(full_inputs, labels=full_inputs)\n","\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9u_UacmPI9TK","executionInfo":{"status":"ok","timestamp":1745908773284,"user_tz":-540,"elapsed":29352,"user":{"displayName":"황준호","userId":"06175040982931986101"}},"outputId":"f48a7d3c-e135-48c1-bc0d-153756d90f67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]}]},{"cell_type":"code","source":["def generate_story(emotion, prompt):\n","  inputs = tokenizer(f'{emotion} {prompt}', return_tensors=\"pt\").to(device)\n","\n","  output = model.generate(\n","      **inputs,\n","      max_new_tokens=50,\n","      temperature=0.9,\n","      top_k=40,\n","      repetition_penalty=1.5,\n","      do_sample=True\n","  )\n","\n","  return tokenizer.decode(output[0], skip_special_tokens=False)"],"metadata":{"id":"ctoV_jzrOEex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_story('<happy>', 'In a magical kingdom'))\n","print(\"=\" * 100)\n","print(generate_story('<sad>', 'In a magical kingdom'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzQ3EERWQQTk","executionInfo":{"status":"ok","timestamp":1745909004701,"user_tz":-540,"elapsed":9495,"user":{"displayName":"황준호","userId":"06175040982931986101"}},"outputId":"fd0f7fe8-0918-4e82-96fd-7c6e4403963f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:1926: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n","  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["<happy> In a magical kingdom in the last.\n","\n","\n",": 1 The Last Man's and, it is not only for (3) \"The point of view- they made that he was on/C I had to make with no end as well . A one or more\n","====================================================================================================\n","<sad> In a magical kingdom in the das and to do it's of that you are not, by using them. The name \"dance\" was called for an attack on those who didn't have no one or any other than mea-kon (in my\n"]}]}]}