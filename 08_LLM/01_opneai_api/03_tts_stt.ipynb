{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw2VGBZ4AHzG",
        "outputId": "c0fdc907-b88d-4cab-8f9f-9573f199da70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhC71YVOBPVi",
        "outputId": "09c3ebde-843b-4cdf-ce8a-eeb6ebddf695"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCle4u0B_Vlj"
      },
      "source": [
        "# TTS (Text To Speech)\n",
        "\n",
        "- TTS 모델은 덱스트를 자연스러운 음성으로 변환하는 AI 모델이다.\n",
        "\n",
        "  - tts-1 : 실시간 텍스트-음성 변환에 최적화된 최신 모델로 속도에 중점. 텍스트를 음성으로 빠르게 변환하는 기능 제공.\n",
        "\n",
        "  - tts-1-hd: 품질에 최적화된 최신 텍스트-음성 변환 모델로 높은 품질에 중점, 음성의 자연스러움과 선명도 강조.\n",
        "  \n",
        "- 음성 선택지\n",
        "  - Alloy: 부드럽고 자연스러운 톤의 음성\n",
        "  - Echo: 명확하고 자신감 있는 음성\n",
        "  - Fable: 이야기 전달에 적합한 서정적인 음성\n",
        "  - Onyx: 전문적이고 신뢰감을 주는 음성\n",
        "  - Nova: 활기차고 에너지 넘치는 음성\n",
        "  - Shimmer: 부드럽고 진정시키는 음성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xbi_XBvOtxsS"
      },
      "outputs": [
        {
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspeech\u001b[38;5;241m.\u001b[39mwith_streaming_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts-1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_text,\n\u001b[1;32m     11\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "input_text = \"현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운 현대 다운\"\n",
        "\n",
        "with client.audio.speech.with_streaming_response.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"fable\",\n",
        "    input=input_text,\n",
        ") as response:\n",
        "  response.stream_to_file(\"현대다운.mp3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rv9Zu5b_aWK"
      },
      "source": [
        "# STT (Speech To Text)\n",
        "\n",
        "- Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성 인식, 음성 번역, 언어 식별 들의 작업을 수행할 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr3GFiHHGa7W",
        "outputId": "7e0b9557-423d-4b21-d56d-522c1be60b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현대다운\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "with open(\"현대다운.mp3\", \"rb\") as f:\n",
        "  transcriptions = client.audio.transcriptions.create(\n",
        "      model=\"whisper-1\",\n",
        "      file=f,\n",
        "      response_format=\"text\",\n",
        "  )\n",
        "  print(transcriptions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "tts = gTTS(text=\"안녕하세요. 현대 다운 입니다. 좋은 하루입니다!\", lang=\"ko\")\n",
        "\n",
        "tts.save('gtts_output.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m==>\u001b[0m \u001b[1mAuto-updating Homebrew...\u001b[0m\n",
            "Adjust how often this is run with HOMEBREW_AUTO_UPDATE_SECS or disable with\n",
            "HOMEBREW_NO_AUTO_UPDATE. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
            "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/portable-ruby/portable-ruby/blobs/sha256:7645e2d653a335798030f6502e7834dfdbeeec5629429a1a34da5dbb2c57d63e\u001b[0m\n",
            "######################################################################### 100.0%\n",
            "\u001b[34m==>\u001b[0m \u001b[1mPouring portable-ruby-3.3.8.arm64_big_sur.bottle.tar.gz\u001b[0m\n",
            "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
            "Updated 2 taps (homebrew/core and homebrew/cask).\n",
            "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
            "dblab           fedify          otterdog        tfcmt           twitch-cli\n",
            "dockerfmt       hub-tool        pyp             tsui\n",
            "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
            "antinote                   dante-via                  font-m-plus-rounded-1c\n",
            "comfyui                    excire-foto                ijhttp\n",
            "companion                  font-exile                 ndi-tools\n",
            "companion-satellite        font-kumar-one-outline     opencloud\n",
            "companion@beta             font-libertinus-math       ovice\n",
            "dante-controller           font-libertinus-mono\n",
            "\n",
            "You have \u001b[1m30\u001b[0m outdated formulae and \u001b[1m1\u001b[0m outdated cask installed.\n",
            "\n",
            "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portaudio/manifests/19.7.0-1\u001b[0m\n",
            "######################################################################### 100.0%\n",
            "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mportaudio\u001b[39m\u001b[0m\n",
            "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portaudio/blobs/sha256:8ad9f1c1\u001b[0m\n",
            "######################################################################### 100.0%\n",
            "\u001b[34m==>\u001b[0m \u001b[1mPouring portaudio--19.7.0.arm64_sequoia.bottle.1.tar.gz\u001b[0m\n",
            "🍺  /opt/homebrew/Cellar/portaudio/19.7.0: 34 files, 546.0KB\n",
            "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup portaudio`...\u001b[0m\n",
            "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
            "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
          ]
        }
      ],
      "source": [
        "!brew install portaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-macosx_11_0_arm64.whl size=24163 sha256=c56f20c320ebf1e80604f7d7b44e817b519996c5ec8fbca4c3b97e2282a9fd6b\n",
            "  Stored in directory: /Users/hwangjunho/Library/Caches/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n"
          ]
        }
      ],
      "source": [
        "!pip install pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "말씀하세요\n",
            "안녕\n",
            "말씀하세요\n"
          ]
        },
        {
          "ename": "UnknownValueError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m말씀하세요\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[0;32m---> 10\u001b[0m txt \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mko-KR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(txt)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:262\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    255\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[1;32m    256\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[1;32m    260\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[1;32m    261\u001b[0m )\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[0;34m(self, response_text)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[0;34m(response_text)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
            "\u001b[0;31mUnknownValueError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 음성 입력 -> 텍스트 출력\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "while True: # 마이크로부터 음성을 계속 입력받기 의한 무한 루프\n",
        "    with sr.Microphone() as source: # 마이크로부터 음성 감지\n",
        "        print(\"말씀하세요\")\n",
        "        audio = recognizer.listen(source)   # 음성 데이터 수집\n",
        "        txt = recognizer.recognize_google(audio, language=\"ko-KR\")  # 음성 -> 텍스트 변환\n",
        "        print(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요 현대 다운입니다 좋은 하루입니다\n"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "# mp3 -> .wav 변환\n",
        "audio = AudioSegment.from_mp3('gtts_output.mp3')\n",
        "audio.export('gtts_output_wav.wav', format='wav')\n",
        "\n",
        "# 파일 로드\n",
        "r = sr.Recognizer()\n",
        "input_audio = sr.AudioFile('gtts_output_wav.wav')\n",
        "\n",
        "# 음성 데이터 -> 텍스트로 변환\n",
        "with input_audio as source:\n",
        "    audio = r.record(source)\n",
        "    \n",
        "result_txt = r.recognize_google(audio_data=audio, language='ko_KR')\n",
        "print(result_txt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pystudy_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
