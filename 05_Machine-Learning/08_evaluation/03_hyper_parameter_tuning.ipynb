{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "- hyper parameter : 모델 설정과 관련해 직접 지정할 수 있는 매개변수\n",
    "- model parameter : 회귀계수(가중치), 절편 등 모델의 학습 대상이 되는 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'n_neighbors': 7}\n",
      "최적의 모델 객체: KNeighborsClassifier(n_neighbors=7)\n",
      "최적회된 점수: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터 로드 \n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 값\n",
    "params = {\n",
    "    'n_neighbors': range(1, 13, 2),\n",
    "}\n",
    "\n",
    "# 첫 번쩨 인자: 모델\n",
    "# 두 번쩨 인자: 데트스 할 파라미터 (딕셔너리)\n",
    "# scoring: 평가 지표 (accuracy, precision, recall, f1)\n",
    "# cv: 반복 횟수\n",
    "grid = GridSearchCV(knn, params, scoring='accuracy', cv=5)\n",
    "grid.fit(iris_input, iris_target)\n",
    "\n",
    "print(\"최적의 파라미터:\", grid.best_params_)\n",
    "print(\"최적의 모델 객체:\", grid.best_estimator_)\n",
    "print(\"최적회된 점수:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "best_knn.fit(iris_input, iris_target)\n",
    "best_knn.score(iris_input, iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV\n",
    "- 하이퍼 파라미터의 값 목록이나 값의 범위를 제공하는데, 이 범위 중에 랜덤하게 값을 뽑아내 최적의 하이퍼 파라미터 조합을 찾는다\n",
    "    - 탐색 범위가 넓을 때 짧은 시간 내에 좋은 결과를 얻을 수 있다.\n",
    "    - 랜덤하게 값을 추출해 계산하므로, 전역 최적값을 놓칠 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'n_neighbors': 5}\n",
      "최적의 모델 객체: KNeighborsClassifier()\n",
      "최적회된 점수: 0.9733333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00038605, 0.00027604, 0.00025306, 0.00020103, 0.00025983,\n",
       "        0.00022259, 0.00020342, 0.00018811, 0.0002213 , 0.00022721]),\n",
       " 'std_fit_time': array([2.55889026e-04, 3.73611575e-05, 3.42462708e-05, 1.34078605e-05,\n",
       "        3.13689998e-05, 3.50596932e-06, 3.56511599e-05, 1.31169227e-05,\n",
       "        5.25257287e-06, 1.94599809e-05]),\n",
       " 'mean_score_time': array([0.00129108, 0.00112357, 0.00114083, 0.00091639, 0.0009995 ,\n",
       "        0.00099206, 0.00069971, 0.00064888, 0.00102911, 0.00098128]),\n",
       " 'std_score_time': array([4.31127627e-04, 1.18263171e-04, 1.21918879e-04, 2.12797129e-04,\n",
       "        5.38917551e-05, 9.69047615e-06, 5.25439931e-05, 1.13289986e-04,\n",
       "        8.66160752e-05, 9.50942179e-05]),\n",
       " 'param_n_neighbors': masked_array(data=[57, 23, 21, 83, 5, 55, 77, 63, 45, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'n_neighbors': 57},\n",
       "  {'n_neighbors': 23},\n",
       "  {'n_neighbors': 21},\n",
       "  {'n_neighbors': 83},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 55},\n",
       "  {'n_neighbors': 77},\n",
       "  {'n_neighbors': 63},\n",
       "  {'n_neighbors': 45},\n",
       "  {'n_neighbors': 9}],\n",
       " 'split0_test_score': array([0.9       , 0.93333333, 0.93333333, 0.66666667, 0.96666667,\n",
       "        0.9       , 0.86666667, 0.9       , 0.9       , 0.96666667]),\n",
       " 'split1_test_score': array([0.93333333, 1.        , 1.        , 0.66666667, 1.        ,\n",
       "        0.93333333, 0.9       , 0.9       , 0.93333333, 1.        ]),\n",
       " 'split2_test_score': array([0.83333333, 0.93333333, 0.93333333, 0.66666667, 0.93333333,\n",
       "        0.83333333, 0.8       , 0.83333333, 0.9       , 0.96666667]),\n",
       " 'split3_test_score': array([0.93333333, 0.93333333, 0.96666667, 0.66666667, 0.96666667,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.96666667, 0.93333333]),\n",
       " 'split4_test_score': array([0.86666667, 1.        , 1.        , 0.63333333, 1.        ,\n",
       "        0.93333333, 0.86666667, 0.86666667, 1.        , 1.        ]),\n",
       " 'mean_test_score': array([0.89333333, 0.96      , 0.96666667, 0.66      , 0.97333333,\n",
       "        0.90666667, 0.87333333, 0.88666667, 0.94      , 0.97333333]),\n",
       " 'std_test_score': array([0.03887301, 0.03265986, 0.02981424, 0.01333333, 0.02494438,\n",
       "        0.03887301, 0.04422166, 0.03399346, 0.03887301, 0.02494438]),\n",
       " 'rank_test_score': array([ 7,  4,  3, 10,  1,  6,  9,  8,  5,  1], dtype=int32)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 생성\n",
    "params = {\n",
    "    'n_neighbors': range(1, 100, 2)\n",
    "}\n",
    "\n",
    "# n_iter: 탐색할 최적의 하이퍼 파라미터 조합 수 (기본값: 10) 값이 크면 시간이 오래 걸림, 값이 작으면 좋은 조합을 찾을 가능성 저하\n",
    "rd_search = RandomizedSearchCV(knn, params, cv=5, n_iter=10, random_state=0)\n",
    "rd_search.fit(iris_input, iris_target)\n",
    "\n",
    "print(\"최적의 파라미터:\", rd_search.best_params_)\n",
    "print(\"최적의 모델 객체:\", rd_search.best_estimator_)\n",
    "print(\"최적회된 점수:\", rd_search.best_score_)\n",
    "rd_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyper.hp클래스**\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>함수명</th>\n",
    "      <th>설명</th>\n",
    "      <th>사용 방법</th>\n",
    "      <th>예시 코드</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>hp.uniform</td>\n",
    "      <td>연속적인 실수 값 샘플링</td>\n",
    "      <td>hp.uniform(label, low, high)</td>\n",
    "      <td><code>hp.uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.quniform</td>\n",
    "      <td>연속적이지만 일정 간격(q)을 갖는 값 샘플링</td>\n",
    "      <td>hp.quniform(label, low, high, q)</td>\n",
    "      <td><code>hp.quniform('num_layers', 1, 5, 1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.loguniform</td>\n",
    "      <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "      <td>hp.loguniform(label, low, high)</td>\n",
    "      <td><code>hp.loguniform('reg_param', -3, 0)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.randint</td>\n",
    "      <td>정수 값 샘플링</td>\n",
    "      <td>hp.randint(label, upper)</td>\n",
    "      <td><code>hp.randint('num_trees', 1, 100)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.choice</td>\n",
    "      <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "      <td>hp.choice(label, options)</td>\n",
    "      <td><code>hp.choice('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.normal</td>\n",
    "      <td>정규분포에서 값 샘플링</td>\n",
    "      <td>hp.normal(label, mean, std)</td>\n",
    "      <td><code>hp.normal('dropout_rate', 0.3, 0.05)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.lognormal</td>\n",
    "      <td>로그 정규분포에서 값 샘플링</td>\n",
    "      <td>hp.lognormal(label, mean, std)</td>\n",
    "      <td><code>hp.lognormal('scale', 0, 1)</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# 검섹 공간\n",
    "search_space = {\n",
    "    'x': hp.quniform('x', -10, 10, 1),\n",
    "    'y': hp.quniform('y', -15, 15, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "# 목적 함수\n",
    "def objective(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    \n",
    "    return{\n",
    "        'loss': x**2 + 20 * y,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 116.07trial/s, best loss: -300.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': np.float64(-0.0), 'y': np.float64(-15.0)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "# 탐색 과정을 저장하는 객체\n",
    "trials = Trials()\n",
    "\n",
    "# fmin() : 목적 함수의 최소값을 찾는 함수\n",
    "best_val = fmin(\n",
    "    fn=objective,           # 목적함수\n",
    "    space=search_space,     # 검색공간\n",
    "    algo=tpe.suggest,       # 베이지안 최적화 적용\n",
    "    max_evals=500,           # 반복 횟수    \n",
    "    trials=trials           # 탐색과정 저장\n",
    ")\n",
    "\n",
    "\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [np.float64(8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0)],\n",
       " 'y': [np.float64(4.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-10.0)]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 탐색과정 -> 목적함수 반환값 (loss와 실행 상태) 저장\n",
    "trials.results\n",
    "\n",
    "# 탐색과정 -> 하이퍼 파라미터값을 딕셔너리(리스트) 형태로 저장\n",
    "trials.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hyperopt를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.95trial/s, best loss: 0.9530516431924881]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': np.float64(0.7465599602392348),\n",
       " 'learning_rate': np.float64(0.1734295530706094),\n",
       " 'max_depth': np.float64(7.0),\n",
       " 'n_estimators': np.float64(100.0)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# 1. 검색 공간\n",
    "search_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "# 2. 목적 함수\n",
    "def xgb_odjective(ss):\n",
    "    \n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=int(ss['n_estimators']),\n",
    "        max_depth=int(ss['max_depth']),\n",
    "        learning_rate=ss['learning_rate'],\n",
    "        colsample_bytree=ss['colsample_bytree']\n",
    "    )\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    return{\n",
    "        'loss': mean_acc,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }\n",
    "\n",
    "# 3. trials() + fmin()\n",
    "trials = Trials()\n",
    "fmin(\n",
    "    fn=xgb_odjective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>함수명</th>\n",
    "            <th>설명</th>\n",
    "            <th>사용 방법</th>\n",
    "            <th>예시 코드</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>suggest_uniform</td>\n",
    "            <td>연속적인 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_uniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_discrete_uniform</td>\n",
    "            <td>연속적이지만 일정 간격(step)을 갖는 값 샘플링</td>\n",
    "            <td>trial.suggest_discrete_uniform(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_discrete_uniform('num_layers', 1, 5, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_loguniform</td>\n",
    "            <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_loguniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_loguniform('reg_param', 1e-3, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_int</td>\n",
    "            <td>정수 값 샘플링</td>\n",
    "            <td>trial.suggest_int(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_int('num_trees', 1, 100)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_categorical</td>\n",
    "            <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "            <td>trial.suggest_categorical(name, choices)</td>\n",
    "            <td><code>trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_float</td>\n",
    "            <td>연속적인 실수 값 샘플링 (<code>step</code> 사용 가능)</td>\n",
    "            <td>trial.suggest_float(name, low, high, step=None, log=False)</td>\n",
    "            <td><code>trial.suggest_float('alpha', 0.1, 1.0, step=0.1)</code></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:32:32,950] A new study created in memory with name: no-name-ca9175d4-9850-467f-9200-c22b20f13fd8\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/1719035818.py:5: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/1719035818.py:6: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-03-28 14:32:32,956] Trial 0 finished with value: 0.40143056865341054 and parameters: {'x': 3.2762215130487093, 'y': -4.4297963132507014}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,959] Trial 1 finished with value: 399.9307399257856 and parameters: {'x': 3.134379624439003, 'y': 14.997816931913373}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,960] Trial 2 finished with value: 20.73026243267226 and parameters: {'x': 5.505285032424765, 'y': -1.1981834159206595}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,960] Trial 3 finished with value: 21.579956015389815 and parameters: {'x': 3.618317033150622, 'y': -0.3959105067445068}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,961] Trial 4 finished with value: 118.25131726555287 and parameters: {'x': 8.920217512333942, 'y': -14.121531772252256}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,962] Trial 5 finished with value: 36.111109822012565 and parameters: {'x': 7.206119067663366, 'y': -0.7081854407894994}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,963] Trial 6 finished with value: 299.5573924078595 and parameters: {'x': -7.444993396343282, 'y': 8.80070669778199}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,963] Trial 7 finished with value: 45.24855061382853 and parameters: {'x': 7.599501132885827, 'y': -9.90847633613635}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,964] Trial 8 finished with value: 330.48219669031005 and parameters: {'x': 9.869737450673437, 'y': 11.831188432464444}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,965] Trial 9 finished with value: 249.7128169187988 and parameters: {'x': -9.518693821842966, 'y': -14.643397840686111}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,974] Trial 10 finished with value: 29.24960580034893 and parameters: {'x': -2.3657549858483256, 'y': -5.676963242866822}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,979] Trial 11 finished with value: 89.30352192681111 and parameters: {'x': 0.3727861653461835, 'y': 4.077514494277314}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,983] Trial 12 finished with value: 1.0007494315670187 and parameters: {'x': 3.998279460777756, 'y': -4.935288720022772}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,987] Trial 13 finished with value: 13.255758267636061 and parameters: {'x': -0.3099393366845504, 'y': -6.516594822325429}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,991] Trial 14 finished with value: 49.37255044806913 and parameters: {'x': -3.8370990800942635, 'y': -6.620687081778374}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:32,995] Trial 15 finished with value: 114.07694388314522 and parameters: {'x': 2.8339345542995886, 'y': 5.679389783638836}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,000] Trial 16 finished with value: 7.05323000199837 and parameters: {'x': 0.6940903550475022, 'y': -3.6824224078584917}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,003] Trial 17 finished with value: 41.62360708696831 and parameters: {'x': 5.277886903622523, 'y': -11.036127760516116}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,009] Trial 18 finished with value: 112.85871463098371 and parameters: {'x': -3.8882643105520898, 'y': 3.087677628278593}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,013] Trial 19 finished with value: 17.800588178309145 and parameters: {'x': 4.909678918609856, 'y': -8.762142289457728}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,017] Trial 20 finished with value: 7.366475388531435 and parameters: {'x': 2.0436842590136224, 'y': -2.4599339394273403}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,022] Trial 21 finished with value: 7.909789726986753 and parameters: {'x': 0.4468575347998215, 'y': -3.8204859986510087}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,026] Trial 22 finished with value: 13.830604190692936 and parameters: {'x': -0.6278333355321997, 'y': -4.1818132974105175}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,031] Trial 23 finished with value: 13.152257659988411 and parameters: {'x': 1.6912332242422847, 'y': -8.382216312813414}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,035] Trial 24 finished with value: 59.63334659001547 and parameters: {'x': -1.7483039733594832, 'y': 1.08990607206663}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,040] Trial 25 finished with value: 3.386773600337852 and parameters: {'x': 4.24418199333685, 'y': -3.643982017894234}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,044] Trial 26 finished with value: 57.98572577806017 and parameters: {'x': 6.428280613030372, 'y': 1.799457170714458}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,049] Trial 27 finished with value: 4.5079018220713465 and parameters: {'x': 4.509452469379596, 'y': -6.4931359833435085}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,054] Trial 28 finished with value: 72.8142596249522 and parameters: {'x': 8.134251449461422, 'y': -11.815696712637344}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,059] Trial 29 finished with value: 6.864738103751296 and parameters: {'x': 3.1593604182557167, 'y': -2.3847863642056586}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,064] Trial 30 finished with value: 11.803693665506563 and parameters: {'x': 6.435174586350861, 'y': -5.05717715274262}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,068] Trial 31 finished with value: 10.066118205085406 and parameters: {'x': 4.747864942385392, 'y': -7.647845605065657}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,072] Trial 32 finished with value: 6.392452752238975 and parameters: {'x': 3.98586547473867, 'y': -2.671798544378672}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,077] Trial 33 finished with value: 21.45817406322165 and parameters: {'x': 1.5541568028219621, 'y': -0.5991237790190418}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,080] Trial 34 finished with value: 51.346726032479694 and parameters: {'x': 4.230265010204393, 'y': -12.05926157874508}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,084] Trial 35 finished with value: 10.141363830195875 and parameters: {'x': 6.079526556638905, 'y': -5.811098031776433}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,089] Trial 36 finished with value: 19.783928830769216 and parameters: {'x': 2.925172088166346, 'y': -9.447283397129064}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,093] Trial 37 finished with value: 15.268552552864843 and parameters: {'x': 3.863261336481422, 'y': -1.1890509819992143}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,097] Trial 38 finished with value: 30.52256215084993 and parameters: {'x': 8.08803204715749, 'y': -7.152787039618245}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,101] Trial 39 finished with value: 7.300184277664636 and parameters: {'x': 5.70137363748749, 'y': -4.947419125604035}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,105] Trial 40 finished with value: 382.6503188239227 and parameters: {'x': 7.071549491913818, 'y': 14.133029126586806}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,109] Trial 41 finished with value: 7.390039356731007 and parameters: {'x': 3.8495403554866545, 'y': -2.4176908509764723}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,113] Trial 42 finished with value: 30.69715098174178 and parameters: {'x': 2.5187728337947553, 'y': 0.5195626091428522}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,117] Trial 43 finished with value: 9.862519816177302 and parameters: {'x': 4.55527215713313, 'y': -2.2716949706046865}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,122] Trial 44 finished with value: 3.8062373551238364 and parameters: {'x': 1.4233184995839643, 'y': -3.8509513494330734}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,126] Trial 45 finished with value: 43.186932442659696 and parameters: {'x': -1.067379124852053, 'y': -10.1617205946639}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,131] Trial 46 finished with value: 4.620034924569035 and parameters: {'x': 1.2658005040525961, 'y': -6.269876778598934}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,135] Trial 47 finished with value: 2.6468925928864153 and parameters: {'x': 2.4208496331189675, 'y': -3.4796456184731204}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,140] Trial 48 finished with value: 146.53182749892568 and parameters: {'x': 2.2460302726726327, 'y': 7.081529586488607}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,144] Trial 49 finished with value: 67.09731315221353 and parameters: {'x': 0.9378832301998581, 'y': 2.9274830545339263}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,148] Trial 50 finished with value: 44.78747465235257 and parameters: {'x': -3.644016101388222, 'y': -4.1971770451421895}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,152] Trial 51 finished with value: 5.766586209291685 and parameters: {'x': 3.2718867945659595, 'y': -7.385930380424444}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,157] Trial 52 finished with value: 4.954953013789203 and parameters: {'x': 5.216215137880313, 'y': -5.208190961425675}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,161] Trial 53 finished with value: 3.145571843435869 and parameters: {'x': 1.9564532577063836, 'y': -3.565921187631499}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,166] Trial 54 finished with value: 11.025946724863969 and parameters: {'x': 0.10791171162739244, 'y': -3.368506188451219}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,172] Trial 55 finished with value: 23.42951293495695 and parameters: {'x': 2.3957339572739667, 'y': -0.19746155824181155}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,178] Trial 56 finished with value: 90.3337330902929 and parameters: {'x': -5.826945046457094, 'y': -1.4759718733926857}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,185] Trial 57 finished with value: 3.064721620039526 and parameters: {'x': 1.3094844809230202, 'y': -4.545160578006462}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,190] Trial 58 finished with value: 32.49819575818562 and parameters: {'x': -1.26361715324733, 'y': -1.2158535270525337}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,194] Trial 59 finished with value: 55.38463889038311 and parameters: {'x': -0.22433937004760063, 'y': 1.7073299096692827}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,200] Trial 60 finished with value: 8.231075390881804 and parameters: {'x': 3.343532121158688, 'y': -7.848343566463501}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,207] Trial 61 finished with value: 1.9527982460734128 and parameters: {'x': 1.796142755750954, 'y': -4.290404353492423}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,212] Trial 62 finished with value: 5.633980443987174 and parameters: {'x': 0.6494211094886775, 'y': -4.670213215137819}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,220] Trial 63 finished with value: 4.389096903992187 and parameters: {'x': 1.8873201621223128, 'y': -3.224882966570184}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,227] Trial 64 finished with value: 0.9545188722452465 and parameters: {'x': 2.5838156686417637, 'y': -5.883917119744348}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,234] Trial 65 finished with value: 1.358473218123311 and parameters: {'x': 2.1984638930116622, 'y': -5.8461755653038505}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,240] Trial 66 finished with value: 0.6082342634965088 and parameters: {'x': 2.7336958137654266, 'y': -5.733018651802565}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,291] Trial 67 finished with value: 176.37740026737848 and parameters: {'x': -9.81344432576238, 'y': -8.491854060233093}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,296] Trial 68 finished with value: 2.1226242430041258 and parameters: {'x': 3.0557902965255574, 'y': -6.455854280420165}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,302] Trial 69 finished with value: 1.0781726396997118 and parameters: {'x': 3.3606095592734135, 'y': -5.973721410599739}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,308] Trial 70 finished with value: 17.91485434390803 and parameters: {'x': 3.5825096325019086, 'y': -9.192318794169942}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,317] Trial 71 finished with value: 0.5510828551936182 and parameters: {'x': 2.749505822880865, 'y': -5.6988100760743405}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,322] Trial 72 finished with value: 5.030747150659874 and parameters: {'x': 5.108539295257382, 'y': -5.764728181130641}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,326] Trial 73 finished with value: 29.461695402914117 and parameters: {'x': 2.6563151960544804, 'y': -10.416971124018573}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,330] Trial 74 finished with value: 7.768034196519554 and parameters: {'x': 5.6786943749756285, 'y': -5.7698250723336315}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,334] Trial 75 finished with value: 67.26757351388744 and parameters: {'x': 3.595698280206977, 'y': -13.180019380957841}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,339] Trial 76 finished with value: 5.426033337334817 and parameters: {'x': 4.379843175481745, 'y': -6.876716853553373}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,343] Trial 77 finished with value: 10.161653044745316 and parameters: {'x': 2.77931525043032, 'y': -8.180086679015634}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,348] Trial 78 finished with value: 6.172099501303437 and parameters: {'x': 0.5646940648372247, 'y': -5.491308969452419}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,353] Trial 79 finished with value: 4.674163060158441 and parameters: {'x': 1.8294544634877097, 'y': -6.817687048726924}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,357] Trial 80 finished with value: 10.364657685262424 and parameters: {'x': 4.091203814500182, 'y': -1.971150066364681}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,362] Trial 81 finished with value: 1.8016120016935642 and parameters: {'x': 3.2451312984394822, 'y': -6.319667627934753}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,366] Trial 82 finished with value: 5.918054785782459 and parameters: {'x': 3.100133700827074, 'y': -7.4306435418919685}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,370] Trial 83 finished with value: 137.80194087379567 and parameters: {'x': -8.736952558218894, 'y': -4.7857909434346}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,375] Trial 84 finished with value: 21.553449811112277 and parameters: {'x': 1.1865272232989859, 'y': -9.273729787817263}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,380] Trial 85 finished with value: 4.997594438077661 and parameters: {'x': 4.845715255849234, 'y': -6.261320590652138}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,384] Trial 86 finished with value: 5.347842686695386 and parameters: {'x': 2.1927854247427403, 'y': -2.832917325945402}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,389] Trial 87 finished with value: 1.1804427192878744 and parameters: {'x': 3.836294527074294, 'y': -4.306419302983815}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,395] Trial 88 finished with value: 10.344961274177098 and parameters: {'x': 6.208693928971447, 'y': -5.2219111181506666}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,400] Trial 89 finished with value: 13.777560531355903 and parameters: {'x': 3.665798420508933, 'y': -8.651612382852774}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,405] Trial 90 finished with value: 8.62666798976855 and parameters: {'x': 4.020016349451346, 'y': -7.754312007856136}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,410] Trial 91 finished with value: 0.8365021584100574 and parameters: {'x': 2.6624376963636394, 'y': -4.149968324370338}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,415] Trial 92 finished with value: 1.115709673455818 and parameters: {'x': 2.7186505240594654, 'y': -6.01811204974885}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,419] Trial 93 finished with value: 0.8843866606890691 and parameters: {'x': 2.5891543767963277, 'y': -4.15407297325156}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,424] Trial 94 finished with value: 12.89489765415097 and parameters: {'x': 4.605345713653343, 'y': -1.7878725439662566}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,428] Trial 95 finished with value: 0.6054662392859536 and parameters: {'x': 2.7614005862408586, 'y': -4.2593674601803215}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,433] Trial 96 finished with value: 4.623539454918225 and parameters: {'x': 2.6499049234087355, 'y': -2.8784503559273515}. Best is trial 0 with value: 0.40143056865341054.\n",
      "[I 2025-03-28 14:32:33,437] Trial 97 finished with value: 0.09466329098026059 and parameters: {'x': 2.8397201984855247, 'y': -5.262628399467272}. Best is trial 97 with value: 0.09466329098026059.\n",
      "[I 2025-03-28 14:32:33,443] Trial 98 finished with value: 4.3025230608131775 and parameters: {'x': 0.9333002283732597, 'y': -5.1768477163300615}. Best is trial 97 with value: 0.09466329098026059.\n",
      "[I 2025-03-28 14:32:33,448] Trial 99 finished with value: 47.940255472346976 and parameters: {'x': 9.582799797884988, 'y': -7.1463928562386565}. Best is trial 97 with value: 0.09466329098026059.\n",
      "[I 2025-03-28 14:32:33,453] Trial 100 finished with value: 9.757813119448876 and parameters: {'x': 0.05373879035044471, 'y': -3.9620414247364124}. Best is trial 97 with value: 0.09466329098026059.\n",
      "[I 2025-03-28 14:32:33,458] Trial 101 finished with value: 0.06757051863609878 and parameters: {'x': 2.849601205343975, 'y': -4.787984148700826}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,463] Trial 102 finished with value: 0.10619730323347393 and parameters: {'x': 3.2135494248253744, 'y': -4.753841623359623}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,468] Trial 103 finished with value: 1.663955100732808 and parameters: {'x': 1.7183452611164438, 'y': -4.853999208803064}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,472] Trial 104 finished with value: 3.46771117112118 and parameters: {'x': 2.9696717972672166, 'y': -3.138067839248653}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,477] Trial 105 finished with value: 1.5650373319609363 and parameters: {'x': 2.360656956535135, 'y': -3.9246964127586943}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,482] Trial 106 finished with value: 17.586999777306165 and parameters: {'x': 4.232710419613041, 'y': -0.9915807606135307}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,487] Trial 107 finished with value: 31.510771267500726 and parameters: {'x': 1.3502801166013187, 'y': 0.3655564085954559}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,492] Trial 108 finished with value: 219.70978131464355 and parameters: {'x': 5.240837226854908, 'y': 9.652249992318065}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,497] Trial 109 finished with value: 22.633616561098073 and parameters: {'x': 6.838019218728655, 'y': -2.1887324855561046}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,502] Trial 110 finished with value: 0.5860457851558432 and parameters: {'x': 3.618851453790679, 'y': -4.549368594861603}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,507] Trial 111 finished with value: 0.5889960631243084 and parameters: {'x': 3.529196471082432, 'y': -4.44416984777883}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,512] Trial 112 finished with value: 0.473094612636899 and parameters: {'x': 3.567727627798246, 'y': -4.6116960555550905}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,516] Trial 113 finished with value: 0.7453221152118065 and parameters: {'x': 3.705703125479917, 'y': -4.502702087376507}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,534] Trial 114 finished with value: 0.4849043330610171 and parameters: {'x': 3.6275183474579995, 'y': -4.698130729181325}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,539] Trial 115 finished with value: 0.4070379338516208 and parameters: {'x': 3.5860381321659225, 'y': -5.252184935115279}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,544] Trial 116 finished with value: 3.1245256825655154 and parameters: {'x': 4.748129946129767, 'y': -5.261853726362359}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,549] Trial 117 finished with value: 9.197291580287022 and parameters: {'x': 5.559519017121408, 'y': -3.373299664572211}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,554] Trial 118 finished with value: 5.760155568240247 and parameters: {'x': 3.4841275565437195, 'y': -2.6493030656345224}. Best is trial 101 with value: 0.06757051863609878.\n",
      "[I 2025-03-28 14:32:33,561] Trial 119 finished with value: 0.05580179060701324 and parameters: {'x': 3.127766998277131, 'y': -5.198689166182419}. Best is trial 119 with value: 0.05580179060701324.\n",
      "[I 2025-03-28 14:32:33,565] Trial 120 finished with value: 4.871127097683928 and parameters: {'x': 4.240655800492613, 'y': -6.825349358996234}. Best is trial 119 with value: 0.05580179060701324.\n",
      "[I 2025-03-28 14:32:33,573] Trial 121 finished with value: 0.22759948643200825 and parameters: {'x': 3.356875012225114, 'y': -5.3166065572304735}. Best is trial 119 with value: 0.05580179060701324.\n",
      "[I 2025-03-28 14:32:33,578] Trial 122 finished with value: 0.032379293733308515 and parameters: {'x': 3.0894494228255307, 'y': -4.843865140056783}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,585] Trial 123 finished with value: 2.155580354680606 and parameters: {'x': 4.454885860058482, 'y': -5.197199109740629}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,590] Trial 124 finished with value: 0.32044887871379 and parameters: {'x': 3.4950508405403578, 'y': -4.725457573417012}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,598] Trial 125 finished with value: 2.2668303213363172 and parameters: {'x': 3.128579400312373, 'y': -3.499900783564091}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,603] Trial 126 finished with value: 3.2399849543465544 and parameters: {'x': 3.97891784886513, 'y': -6.5105312971004015}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,610] Trial 127 finished with value: 0.9103279411069187 and parameters: {'x': 2.0499364704505108, 'y': -4.912209163764744}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,619] Trial 128 finished with value: 0.23306039047894297 and parameters: {'x': 3.261211383563837, 'y': -5.405991383622373}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,625] Trial 129 finished with value: 9.032500378359778 and parameters: {'x': 4.834218809899573, 'y': -7.380785949171066}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,632] Trial 130 finished with value: 0.3046662585497125 and parameters: {'x': 3.1189989961565456, 'y': -5.538985618976469}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,639] Trial 131 finished with value: 0.45363492822789164 and parameters: {'x': 3.173989930226707, 'y': -5.650663071341533}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,645] Trial 132 finished with value: 0.19232352096352495 and parameters: {'x': 3.1660530927704995, 'y': -5.4058939410053775}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,651] Trial 133 finished with value: 0.32873561326939044 and parameters: {'x': 3.1139074793961874, 'y': -5.561925884264996}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,657] Trial 134 finished with value: 9.048636599497456 and parameters: {'x': 3.2498262555046, 'y': -7.997703027579284}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,663] Trial 135 finished with value: 2.488691372482582 and parameters: {'x': 2.176113239745724, 'y': -6.345325974907307}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,671] Trial 136 finished with value: 0.25293157981907527 and parameters: {'x': 3.056256047470422, 'y': -5.499766782551703}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,676] Trial 137 finished with value: 5.782478351407775 and parameters: {'x': 1.6020558190567322, 'y': -6.956586419858482}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,684] Trial 138 finished with value: 1.3444704136377155 and parameters: {'x': 4.065975348585759, 'y': -5.456253186120584}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,690] Trial 139 finished with value: 2.163172180177086 and parameters: {'x': 3.1633105241826303, 'y': -3.5383222472554765}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,697] Trial 140 finished with value: 2.799747527361951 and parameters: {'x': 2.2103934072771314, 'y': -6.475218274049821}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,703] Trial 141 finished with value: 0.1518453958981592 and parameters: {'x': 2.9429237825007775, 'y': -5.385470752838838}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,708] Trial 142 finished with value: 2.1761630623365105 and parameters: {'x': 4.434757280152827, 'y': -5.342979021785548}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,715] Trial 143 finished with value: 1.0516481854133604 and parameters: {'x': 3.117628734263705, 'y': -6.018730418849304}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,720] Trial 144 finished with value: 4.3114788072936285 and parameters: {'x': 2.9762684720389663, 'y': -7.076274457260952}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,726] Trial 145 finished with value: 0.6750282837645857 and parameters: {'x': 2.193439965621525, 'y': -5.156490238379201}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,733] Trial 146 finished with value: 2.08382245937171 and parameters: {'x': 3.960318765351436, 'y': -3.922219721703165}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,740] Trial 147 finished with value: 1.3108787954452963 and parameters: {'x': 2.48592031172038, 'y': -6.02303512625111}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,745] Trial 148 finished with value: 5.103767199373063 and parameters: {'x': 1.6427703969348009, 'y': -3.193983664543273}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,750] Trial 149 finished with value: 7.223197498488327 and parameters: {'x': 3.451844684190445, 'y': -7.6493459343500545}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,758] Trial 150 finished with value: 2.760693244709681 and parameters: {'x': 2.9585432969426906, 'y': -6.661016130710746}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,763] Trial 151 finished with value: 0.3912163522061401 and parameters: {'x': 3.250610216856969, 'y': -5.573071436570558}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,815] Trial 152 finished with value: 1.1480873465261625 and parameters: {'x': 3.9778753284161295, 'y': -5.438003639940594}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,825] Trial 153 finished with value: 1.6683754224476046 and parameters: {'x': 2.5044425179305216, 'y': -3.8071889485704102}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,830] Trial 154 finished with value: 0.17483617611680183 and parameters: {'x': 3.4168579668716306, 'y': -4.967356293524595}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,836] Trial 155 finished with value: 1.156561148167213 and parameters: {'x': 2.9237347027170784, 'y': -6.072727715964103}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,842] Trial 156 finished with value: 2.0708900562362738 and parameters: {'x': 4.4093119150631015, 'y': -4.708915850143902}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,849] Trial 157 finished with value: 0.18568795040642982 and parameters: {'x': 3.3907457825890344, 'y': -4.818325335295994}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,855] Trial 158 finished with value: 1.3472509751733066 and parameters: {'x': 1.8468783575392798, 'y': -4.867480368012896}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,860] Trial 159 finished with value: 0.9678520967093763 and parameters: {'x': 3.3194239802319565, 'y': -4.069505283431361}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,866] Trial 160 finished with value: 1.3216974007110869 and parameters: {'x': 3.8692999837675526, 'y': -5.752339643334591}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,871] Trial 161 finished with value: 0.08137912581546158 and parameters: {'x': 2.7978195332176647, 'y': -4.79874845424907}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,876] Trial 162 finished with value: 0.3809085704839687 and parameters: {'x': 2.422246732888747, 'y': -4.782952233768136}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,882] Trial 163 finished with value: 0.21041697032472 and parameters: {'x': 2.6426981425761014, 'y': -4.712332912890348}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,888] Trial 164 finished with value: 0.7401414693093064 and parameters: {'x': 2.7431926316066972, 'y': -4.178908382183685}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,894] Trial 165 finished with value: 2.318514222815016 and parameters: {'x': 1.9937474651505247, 'y': -6.142790470263041}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,899] Trial 166 finished with value: 105.16352813785693 and parameters: {'x': 2.7595312430971672, 'y': 5.25210724265068}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,905] Trial 167 finished with value: 5.361747046332568 and parameters: {'x': 3.814386817122238, 'y': -2.8323927573404637}. Best is trial 122 with value: 0.032379293733308515.\n",
      "[I 2025-03-28 14:32:33,911] Trial 168 finished with value: 0.003564917077843593 and parameters: {'x': 2.971514061997217, 'y': -5.052473502017163}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,917] Trial 169 finished with value: 3.5063587348944463 and parameters: {'x': 1.1305537837166306, 'y': -4.8926241213389146}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,923] Trial 170 finished with value: 2.0918652616631648 and parameters: {'x': 2.3811534081882506, 'y': -3.6927532147807183}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,929] Trial 171 finished with value: 0.24092372731049772 and parameters: {'x': 3.3863704670134, 'y': -5.302723619049365}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,934] Trial 172 finished with value: 0.3199167311069139 and parameters: {'x': 3.474267415377922, 'y': -4.691800146304935}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,941] Trial 173 finished with value: 3.127650867786856 and parameters: {'x': 2.8561783853092244, 'y': -6.762658847007723}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,948] Trial 174 finished with value: 1.978380002302221 and parameters: {'x': 4.246163564749866, 'y': -4.347729831900823}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,953] Trial 175 finished with value: 0.36469384785487347 and parameters: {'x': 3.488708059405645, 'y': -5.354765106129171}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,958] Trial 176 finished with value: 3.3755527343186076 and parameters: {'x': 2.9318758822054543, 'y': -3.1639956865809595}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,965] Trial 177 finished with value: 2.452202530436718 and parameters: {'x': 2.3578812287183335, 'y': -6.4282457820712935}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,970] Trial 178 finished with value: 90.5662096352088 and parameters: {'x': -6.449278485341692, 'y': -3.8698027863830866}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,979] Trial 179 finished with value: 0.6735053963177825 and parameters: {'x': 3.820458439208578, 'y': -4.981202504177234}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,988] Trial 180 finished with value: 1.1065959891133839 and parameters: {'x': 3.2683826059542023, 'y': -6.017136552255701}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:33,994] Trial 181 finished with value: 0.4944297827384444 and parameters: {'x': 3.5328469835102294, 'y': -4.541192987300223}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,000] Trial 182 finished with value: 0.19656000151968922 and parameters: {'x': 3.3856833238736983, 'y': -5.218651263900818}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,008] Trial 183 finished with value: 0.265369779192894 and parameters: {'x': 2.645815263250212, 'y': -5.374062764046861}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,016] Trial 184 finished with value: 1.4434033520541312 and parameters: {'x': 1.9544599265098828, 'y': -5.591818643488367}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,024] Trial 185 finished with value: 0.21067269689452983 and parameters: {'x': 2.6663510286022736, 'y': -5.31520003296283}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,030] Trial 186 finished with value: 5.321565685855624 and parameters: {'x': 2.5022504606139973, 'y': -7.252512171309324}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,039] Trial 187 finished with value: 0.07172755944095163 and parameters: {'x': 2.768484620988031, 'y': -5.134640962273359}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,046] Trial 188 finished with value: 0.7431339220895966 and parameters: {'x': 2.862974586618284, 'y': -4.148907785150653}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,053] Trial 189 finished with value: 3.533940157875562 and parameters: {'x': 1.9425095742691576, 'y': -6.554237484222782}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,061] Trial 190 finished with value: 4.025323275572393 and parameters: {'x': 1.5648253213759016, 'y': -3.598002525890789}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,068] Trial 191 finished with value: 38.5296614285883 and parameters: {'x': -3.2032374710168963, 'y': -5.222500127550972}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,075] Trial 192 finished with value: 0.1522458530422814 and parameters: {'x': 2.6308727234486673, 'y': -5.126455157063986}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,084] Trial 193 finished with value: 1.0191279069033838 and parameters: {'x': 3.118430363421503, 'y': -6.002547832237063}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,093] Trial 194 finished with value: 0.44117093782419187 and parameters: {'x': 2.3365345402967135, 'y': -5.0313770872596315}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,100] Trial 195 finished with value: 1.1935986012075528 and parameters: {'x': 3.8473371726250702, 'y': -4.310349133912452}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,106] Trial 196 finished with value: 1.0992543496272524 and parameters: {'x': 2.8615801624582735, 'y': -6.039275852794711}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,113] Trial 197 finished with value: 97.87139151167847 and parameters: {'x': 3.322646345501684, 'y': -14.887734363716133}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,119] Trial 198 finished with value: 0.7384378032970972 and parameters: {'x': 2.2249679219549474, 'y': -4.628835506414926}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,127] Trial 199 finished with value: 1.4864188584883964 and parameters: {'x': 4.203329866295295, 'y': -5.196000233086962}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,133] Trial 200 finished with value: 0.5516878059032747 and parameters: {'x': 2.7867039029534566, 'y': -5.71147212235476}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,141] Trial 201 finished with value: 0.26280792963812244 and parameters: {'x': 2.5141971245258445, 'y': -5.163717732146413}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,147] Trial 202 finished with value: 0.41835090097096683 and parameters: {'x': 3.203393484292995, 'y': -4.386011407664506}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,155] Trial 203 finished with value: 0.22903075083034294 and parameters: {'x': 2.5235089845751664, 'y': -5.044576485390325}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,161] Trial 204 finished with value: 2.310697435881322 and parameters: {'x': 3.7788070414800687, 'y': -6.305433655159229}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,167] Trial 205 finished with value: 0.9535672623928838 and parameters: {'x': 2.97894693207727, 'y': -4.023719286924132}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,173] Trial 206 finished with value: 0.794988554490375 and parameters: {'x': 3.586735187584824, 'y': -5.67136456127813}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,181] Trial 207 finished with value: 0.9094629713468193 and parameters: {'x': 2.0528366797100808, 'y': -4.888893672348533}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,187] Trial 208 finished with value: 372.7798871729851 and parameters: {'x': 2.6756980445037355, 'y': 14.304784780324448}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,193] Trial 209 finished with value: 3.3454908424644514 and parameters: {'x': 3.306440928843368, 'y': -6.803215128484138}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,201] Trial 210 finished with value: 1.7169928616106458 and parameters: {'x': 3.014219945755318, 'y': -3.6897364178328997}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,207] Trial 211 finished with value: 0.3334843115104426 and parameters: {'x': 2.4231152713943374, 'y': -4.9737641197591245}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,214] Trial 212 finished with value: 0.233080987528358 and parameters: {'x': 2.6385082543502447, 'y': -5.320007352033435}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,222] Trial 213 finished with value: 0.8039626999711159 and parameters: {'x': 3.373341312362513, 'y': -5.8152171271842565}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,229] Trial 214 finished with value: 0.6657007864116653 and parameters: {'x': 2.58288120289158, 'y': -4.298777713196101}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,250] Trial 215 finished with value: 0.1712421124825801 and parameters: {'x': 2.972171340754825, 'y': -5.412877316169339}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,256] Trial 216 finished with value: 0.7515410720458778 and parameters: {'x': 2.141462569959089, 'y': -4.879772909605922}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,263] Trial 217 finished with value: 2.3846700285350337 and parameters: {'x': 3.7854996981850886, 'y': -6.329533847890368}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,270] Trial 218 finished with value: 0.35223573033494987 and parameters: {'x': 2.776800646675899, 'y': -4.450074751433749}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,277] Trial 219 finished with value: 2.056483564620922 and parameters: {'x': 1.6197150873432256, 'y': -5.388969310502773}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,283] Trial 220 finished with value: 1.9159542418946125 and parameters: {'x': 4.092581811045576, 'y': -5.849834823990511}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,290] Trial 221 finished with value: 0.10556225555871074 and parameters: {'x': 3.0963666268259624, 'y': -5.3102833040833755}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,298] Trial 222 finished with value: 0.10901286181994953 and parameters: {'x': 3.3301610601761804, 'y': -4.997443407875687}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,305] Trial 223 finished with value: 0.10417073822463803 and parameters: {'x': 2.9459122510584956, 'y': -4.681809406740113}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,311] Trial 224 finished with value: 2.4059129211054615 and parameters: {'x': 3.084429932949613, 'y': -3.4511990097086116}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,317] Trial 225 finished with value: 0.6201662711895375 and parameters: {'x': 3.644117607945481, 'y': -4.546922988528298}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,323] Trial 226 finished with value: 0.7635425965079398 and parameters: {'x': 3.082823955174332, 'y': -4.130124842889958}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,329] Trial 227 finished with value: 0.4389749888100817 and parameters: {'x': 2.3551963588532576, 'y': -4.847673859190273}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,335] Trial 228 finished with value: 1.2599207987790957 and parameters: {'x': 3.3743079494287445, 'y': -6.05821281308324}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,341] Trial 229 finished with value: 1.5812611359210893 and parameters: {'x': 2.6961712913593288, 'y': -3.779774917596417}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,347] Trial 230 finished with value: 0.6396241128563108 and parameters: {'x': 3.786949774704281, 'y': -4.857402086448672}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,353] Trial 231 finished with value: 0.10368267306047257 and parameters: {'x': 2.909155217713111, 'y': -5.308917300570428}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,359] Trial 232 finished with value: 0.39199032165621367 and parameters: {'x': 2.892593167853751, 'y': -5.6168096092511215}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,365] Trial 233 finished with value: 0.03724375105374885 and parameters: {'x': 3.190129785501907, 'y': -5.033081954578709}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,371] Trial 234 finished with value: 0.936635062836062 and parameters: {'x': 2.225411732288687, 'y': -4.419786178758168}. Best is trial 168 with value: 0.003564917077843593.\n",
      "[I 2025-03-28 14:32:34,377] Trial 235 finished with value: 0.0019013498280167108 and parameters: {'x': 2.962631829844541, 'y': -5.022471530594274}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,383] Trial 236 finished with value: 1.6306501652509622 and parameters: {'x': 3.3894636414286383, 'y': -6.216128380252721}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,390] Trial 237 finished with value: 0.26046607722218384 and parameters: {'x': 2.9487763054957403, 'y': -4.492218343829242}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,396] Trial 238 finished with value: 0.491130577051009 and parameters: {'x': 3.7004285691741887, 'y': -5.023030339459237}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,401] Trial 239 finished with value: 1.1074445043951027 and parameters: {'x': 3.0573524885968753, 'y': -3.949212106823243}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,407] Trial 240 finished with value: 5.440112430803797 and parameters: {'x': 4.119631820504688, 'y': -2.9538971146794317}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,413] Trial 241 finished with value: 0.17218344078035192 and parameters: {'x': 2.6074351173879053, 'y': -5.134447959151875}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,418] Trial 242 finished with value: 0.4812666073380576 and parameters: {'x': 2.7602658579288875, 'y': -5.650994737661899}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,425] Trial 243 finished with value: 0.11789952330479604 and parameters: {'x': 3.339206818103195, 'y': -5.053275302505965}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,431] Trial 244 finished with value: 0.0351431328052202 and parameters: {'x': 2.931191755471173, 'y': -4.825619501405457}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,436] Trial 245 finished with value: 0.28068224245384776 and parameters: {'x': 3.37556168467269, 'y': -4.626321443671625}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,442] Trial 246 finished with value: 0.8015411018857868 and parameters: {'x': 2.984203421493445, 'y': -4.104851090603763}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,448] Trial 247 finished with value: 1.0146238513172543 and parameters: {'x': 2.0032601783012858, 'y': -4.854626071260113}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,453] Trial 248 finished with value: 0.8563013794519844 and parameters: {'x': 3.4229742715159963, 'y': -5.823039576865837}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,496] Trial 249 finished with value: 0.6283417086210049 and parameters: {'x': 2.411433587448676, 'y': -4.46902797942126}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,508] Trial 250 finished with value: 1.948615188748733 and parameters: {'x': 3.1185104140062134, 'y': -3.609111625427544}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,514] Trial 251 finished with value: 2.375617127830722 and parameters: {'x': 3.730390071571972, 'y': -6.357257334177941}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,519] Trial 252 finished with value: 282.8981729410545 and parameters: {'x': 2.808264601243103, 'y': 11.818484190851388}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,526] Trial 253 finished with value: 0.29910396225607133 and parameters: {'x': 2.4774319165755996, 'y': -5.161327494377804}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,532] Trial 254 finished with value: 0.6082678407382592 and parameters: {'x': 3.235119391562765, 'y': -5.743630763517362}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,538] Trial 255 finished with value: 0.39694280986355807 and parameters: {'x': 3.6217983366889737, 'y': -4.898463610688661}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,546] Trial 256 finished with value: 1.8057142589861024 and parameters: {'x': 2.0243457917882113, 'y': -4.075979910940931}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,552] Trial 257 finished with value: 5.028622010572143 and parameters: {'x': 4.57435434052762, 'y': -6.596881467433944}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,560] Trial 258 finished with value: 0.125092501286474 and parameters: {'x': 2.9139093479995255, 'y': -5.343046499653629}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,568] Trial 259 finished with value: 0.479241110289657 and parameters: {'x': 3.002004633460341, 'y': -5.692269522465309}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,575] Trial 260 finished with value: 1.1879519826108365 and parameters: {'x': 4.064981618128664, 'y': -5.231875258833038}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,581] Trial 261 finished with value: 3.9493727295045584 and parameters: {'x': 3.4663455157363856, 'y': -6.9318112199325075}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,587] Trial 262 finished with value: 1.0278898564923202 and parameters: {'x': 3.0185981693270594, 'y': -6.013678432536671}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,593] Trial 263 finished with value: 0.5246834682507359 and parameters: {'x': 2.346368384501503, 'y': -5.312168511338926}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,601] Trial 264 finished with value: 0.9141298797588194 and parameters: {'x': 3.8095395815846143, 'y': -4.491300141923917}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,608] Trial 265 finished with value: 2.8557343681253924 and parameters: {'x': 2.790368028558302, 'y': -3.3231610677602754}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,614] Trial 266 finished with value: 1.5045951390656662 and parameters: {'x': 3.415360616935838, 'y': -6.154153671295268}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,620] Trial 267 finished with value: 24.639600847450662 and parameters: {'x': 7.963749907399544, 'y': -4.971933930776102}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,629] Trial 268 finished with value: 0.8973947113333247 and parameters: {'x': 3.072827464459419, 'y': -4.055494377066109}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,636] Trial 269 finished with value: 0.4630297089041864 and parameters: {'x': 2.5386286193330996, 'y': -5.5001661304063925}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,643] Trial 270 finished with value: 1.6051502808954239 and parameters: {'x': 4.201059523835626, 'y': -4.596755283854627}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,650] Trial 271 finished with value: 2.462350941292848 and parameters: {'x': 3.375204890149534, 'y': -6.523670644102827}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,657] Trial 272 finished with value: 1.4408219849825321 and parameters: {'x': 1.827184078543434, 'y': -5.255587165875984}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,665] Trial 273 finished with value: 0.9835448712957136 and parameters: {'x': 3.7689999822542766, 'y': -4.373754122896896}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,672] Trial 274 finished with value: 68.79913651023551 and parameters: {'x': 2.76301216646415, 'y': -13.29113823772053}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,680] Trial 275 finished with value: 1.3325988400734512 and parameters: {'x': 2.1549622155403867, 'y': -5.786454056451513}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,688] Trial 276 finished with value: 1.4803927060316584 and parameters: {'x': 3.174737069583033, 'y': -3.795898815487173}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,693] Trial 277 finished with value: 0.24800860042896108 and parameters: {'x': 2.5054788001745045, 'y': -4.941200481701689}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,701] Trial 278 finished with value: 0.8313706634179834 and parameters: {'x': 3.6066910850096585, 'y': -5.680658938667367}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,720] Trial 279 finished with value: 4.9599613123173905 and parameters: {'x': 2.8968028064902254, 'y': -7.224704845944535}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,728] Trial 280 finished with value: 27.88734449015556 and parameters: {'x': -2.275661040569799, 'y': -4.766023344819321}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,735] Trial 281 finished with value: 1.8624776087783221 and parameters: {'x': 3.255464990703419, 'y': -6.34060256873662}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,742] Trial 282 finished with value: 73.0397971115666 and parameters: {'x': -0.6090495146426365, 'y': 2.7469063962606617}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,750] Trial 283 finished with value: 3.6058028360576015 and parameters: {'x': 4.008036348458528, 'y': -3.390756216030648}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,756] Trial 284 finished with value: 1.17117649998931 and parameters: {'x': 2.278721367651692, 'y': -4.193195417398324}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,763] Trial 285 finished with value: 6.176203412248201 and parameters: {'x': 2.7117515602475586, 'y': -2.5315761609422736}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,769] Trial 286 finished with value: 2.2454836179410993 and parameters: {'x': 1.5297178023136686, 'y': -5.289402621114168}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,775] Trial 287 finished with value: 0.9074119493881598 and parameters: {'x': 3.161320504109321, 'y': -5.938822477544117}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,781] Trial 288 finished with value: 0.4072174739122889 and parameters: {'x': 3.6256153230581405, 'y': -4.8742107259455425}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,787] Trial 289 finished with value: 2.913657947434348 and parameters: {'x': 4.425533595425419, 'y': -4.061111340068575}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,793] Trial 290 finished with value: 0.3039640721463228 and parameters: {'x': 2.7821285566169505, 'y': -5.506454446425845}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,800] Trial 291 finished with value: 0.28553134018306536 and parameters: {'x': 3.3450159885239175, 'y': -4.591961634345581}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,805] Trial 292 finished with value: 3.736656753133145 and parameters: {'x': 2.1760513502478878, 'y': -6.748646726959112}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,811] Trial 293 finished with value: 65.05362317206283 and parameters: {'x': -5.061648171159576, 'y': -5.2518966782279985}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,817] Trial 294 finished with value: 2.0600643947137454 and parameters: {'x': 3.9825481556108526, 'y': -6.046261686491222}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,823] Trial 295 finished with value: 1.855615870366821 and parameters: {'x': 3.0269027297747657, 'y': -3.6380557597693337}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,829] Trial 296 finished with value: 0.4481463653131953 and parameters: {'x': 2.550814720979801, 'y': -4.5036342574021235}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,835] Trial 297 finished with value: 0.3213003752870458 and parameters: {'x': 3.5480250789907193, 'y': -5.1448063813658145}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,841] Trial 298 finished with value: 1.9175136108566488 and parameters: {'x': 1.885935926958996, 'y': -5.822420118927022}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,848] Trial 299 finished with value: 0.9031537396811092 and parameters: {'x': 2.940465116538454, 'y': -4.051522621602218}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,853] Trial 300 finished with value: 4.505969163177182 and parameters: {'x': 2.451029952173637, 'y': -2.9494876128716747}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,859] Trial 301 finished with value: 0.11564450792901021 and parameters: {'x': 3.32495788592519, 'y': -4.899765872558088}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,865] Trial 302 finished with value: 126.10182979279655 and parameters: {'x': -8.223769504062204, 'y': -4.641073945665954}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,870] Trial 303 finished with value: 2.466213240818841 and parameters: {'x': 3.806613793901322, 'y': -6.347437355986154}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,877] Trial 304 finished with value: 39.45512669337231 and parameters: {'x': 2.9705028757547445, 'y': -11.281262342318904}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,884] Trial 305 finished with value: 0.24088743251600497 and parameters: {'x': 3.277658206821816, 'y': -5.404713914636622}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,891] Trial 306 finished with value: 0.7000748851220218 and parameters: {'x': 2.606866865451127, 'y': -4.26140591415731}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,897] Trial 307 finished with value: 0.6940868172424792 and parameters: {'x': 2.182450062518872, 'y': -4.839691182503635}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,903] Trial 308 finished with value: 150.62731668038336 and parameters: {'x': 4.945059264625901, 'y': 7.117923136308312}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,909] Trial 309 finished with value: 0.750006067784852 and parameters: {'x': 3.613630669109222, 'y': -5.611116576205736}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,915] Trial 310 finished with value: 3.7850767002250665 and parameters: {'x': 4.196018458668584, 'y': -3.4655240155841174}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,921] Trial 311 finished with value: 3.102296206309822 and parameters: {'x': 2.8660734468554994, 'y': -6.756234575639785}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,927] Trial 312 finished with value: 0.10998357860772001 and parameters: {'x': 3.240943435290256, 'y': -4.772118803763342}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,933] Trial 313 finished with value: 1.2265414608626102 and parameters: {'x': 3.23302534666125, 'y': -3.9172993725521286}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,939] Trial 314 finished with value: 0.36648613414050885 and parameters: {'x': 2.4597908787043594, 'y': -4.7267597405038915}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,945] Trial 315 finished with value: 2.001224328022539 and parameters: {'x': 1.7757296359327692, 'y': -4.291207785250692}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,951] Trial 316 finished with value: 0.6920487083690532 and parameters: {'x': 3.8302585582902857, 'y': -5.0521481999189755}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,956] Trial 317 finished with value: 1.1262893824992422 and parameters: {'x': 2.7173628929753626, 'y': -6.022939708991681}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,962] Trial 318 finished with value: 2.2120179056506344 and parameters: {'x': 3.483370441722486, 'y': -3.593454258930893}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:34,991] Trial 319 finished with value: 0.10786630931481593 and parameters: {'x': 3.0176507219161746, 'y': -4.672044574171041}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,013] Trial 320 finished with value: 6.732087774471484 and parameters: {'x': 1.3195330428111955, 'y': -3.0231038013420926}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,020] Trial 321 finished with value: 1.140281176799396 and parameters: {'x': 2.2010034044547346, 'y': -4.2915611408833705}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,026] Trial 322 finished with value: 0.4985997226049591 and parameters: {'x': 2.9053849619132732, 'y': -5.699748324165772}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,032] Trial 323 finished with value: 0.025612942039467 and parameters: {'x': 3.1181569001780627, 'y': -5.107943915899778}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,037] Trial 324 finished with value: 1.5999229504691317 and parameters: {'x': 2.5190626207236866, 'y': -6.169881270763817}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,043] Trial 325 finished with value: 6.4722868110194485 and parameters: {'x': 2.9810551019756186, 'y': -7.543998408383601}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,049] Trial 326 finished with value: 0.42361338477947025 and parameters: {'x': 2.3954103900499817, 'y': -5.241007859456813}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,056] Trial 327 finished with value: 0.23243433493983454 and parameters: {'x': 3.0360411103324934, 'y': -4.519234596392549}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,062] Trial 328 finished with value: 1.189482801893757 and parameters: {'x': 2.706821698806342, 'y': -3.949509978342032}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,068] Trial 329 finished with value: 1.5071563818863711 and parameters: {'x': 1.8942074697398583, 'y': -5.533272221203434}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,073] Trial 330 finished with value: 0.12453274212709149 and parameters: {'x': 3.344532541879694, 'y': -4.9236451068168625}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,081] Trial 331 finished with value: 1.8890677740523631 and parameters: {'x': 4.361675996655917, 'y': -4.813167844888845}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,087] Trial 332 finished with value: 3.041879553501709 and parameters: {'x': 3.8658843114107864, 'y': -6.513976192928534}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,092] Trial 333 finished with value: 1.6264520020922126 and parameters: {'x': 3.344970522533477, 'y': -3.772218528941248}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,098] Trial 334 finished with value: 1.1429549096440765 and parameters: {'x': 3.6579907432386314, 'y': -5.842616811757486}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,104] Trial 335 finished with value: 0.3093063905192297 and parameters: {'x': 3.1708764479868687, 'y': -4.470748046727628}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,110] Trial 336 finished with value: 1.1791795827527778 and parameters: {'x': 4.0751513324378275, 'y': -5.152411269629059}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,115] Trial 337 finished with value: 37.68486511081517 and parameters: {'x': 3.126198058149268, 'y': 1.1375026811346098}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,122] Trial 338 finished with value: 48.57528293850743 and parameters: {'x': 9.149430597612318, 'y': -1.7197886861275475}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,128] Trial 339 finished with value: 3.42080691610658 and parameters: {'x': 3.613073829129576, 'y': -3.2550222362038594}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,133] Trial 340 finished with value: 3.8571327267925377 and parameters: {'x': 2.8102865915655264, 'y': -6.954774040510236}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,139] Trial 341 finished with value: 21.344696528224862 and parameters: {'x': 2.26154068185018, 'y': -0.4393668900400941}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,157] Trial 342 finished with value: 0.45805421009446556 and parameters: {'x': 3.354960497624827, 'y': -5.576244093436454}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,163] Trial 343 finished with value: 3.302381861917159 and parameters: {'x': 4.741599496853174, 'y': -4.481142548981002}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,169] Trial 344 finished with value: 6.901431221771516 and parameters: {'x': 2.9554488550377496, 'y': -2.3733202674756733}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,175] Trial 345 finished with value: 1.88308077559273 and parameters: {'x': 3.8180562604436528, 'y': -6.101755295127587}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,181] Trial 346 finished with value: 4.44221057471909 and parameters: {'x': 0.8926514578619655, 'y': -5.035954091113411}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,188] Trial 347 finished with value: 1.3891866156003616 and parameters: {'x': 3.4103116833224343, 'y': -3.8950878142904424}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,194] Trial 348 finished with value: 0.22951534165424176 and parameters: {'x': 2.5856816269399943, 'y': -4.759468032479773}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,199] Trial 349 finished with value: 19.548024839685876 and parameters: {'x': -1.3825184213732555, 'y': -5.584428888753751}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,205] Trial 350 finished with value: 1.5149007767678588 and parameters: {'x': 2.066164232830812, 'y': -4.198219770308975}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,211] Trial 351 finished with value: 1.8456089321041245 and parameters: {'x': 3.185751139296078, 'y': -6.345773177899728}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,217] Trial 352 finished with value: 0.09408809183407922 and parameters: {'x': 2.735512785885185, 'y': -5.155353163481994}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,223] Trial 353 finished with value: 0.3979601372833452 and parameters: {'x': 2.3727580393709156, 'y': -4.9327121102312805}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,229] Trial 354 finished with value: 2.261381564628955 and parameters: {'x': 2.832173034218905, 'y': -3.5056052482072664}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,235] Trial 355 finished with value: 2.0356742520158644 and parameters: {'x': 4.243784891256212, 'y': -4.300948216296791}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,241] Trial 356 finished with value: 1.0357751296453634 and parameters: {'x': 3.626227036481972, 'y': -5.802256086561124}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,246] Trial 357 finished with value: 1.8223146594381716 and parameters: {'x': 1.6525273634186548, 'y': -5.081438032286454}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,252] Trial 358 finished with value: 0.4777453682888589 and parameters: {'x': 2.6642318390607396, 'y': -4.395843471947604}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,258] Trial 359 finished with value: 0.14806766336890764 and parameters: {'x': 3.190173611882023, 'y': -5.3345170559368436}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,264] Trial 360 finished with value: 4.705332505965137 and parameters: {'x': 3.8543477906560653, 'y': -6.993846122088221}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,270] Trial 361 finished with value: 1.55762349775652 and parameters: {'x': 3.163115874702198, 'y': -6.237342599758311}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,276] Trial 362 finished with value: 0.4639591543698816 and parameters: {'x': 3.4492020255822284, 'y': -5.5120319273079605}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,283] Trial 363 finished with value: 2.912303834130814 and parameters: {'x': 4.118693700839158, 'y': -3.7112687487945353}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,289] Trial 364 finished with value: 0.09092652617144573 and parameters: {'x': 3.200097843678452, 'y': -4.774417688799233}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,295] Trial 365 finished with value: 5.557645718209958 and parameters: {'x': 3.6113268720451455, 'y': -2.723176516783645}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,301] Trial 366 finished with value: 0.12676272201393624 and parameters: {'x': 3.1520887025508246, 'y': -4.678081145984981}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,308] Trial 367 finished with value: 3.494305972958265 and parameters: {'x': 2.1788866182892725, 'y': -3.3206909792019106}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,315] Trial 368 finished with value: 2.7312102416765023 and parameters: {'x': 4.435972613896511, 'y': -4.181957889949592}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,321] Trial 369 finished with value: 0.14571157166957527 and parameters: {'x': 3.2878087593562424, 'y': -4.749245758346153}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,328] Trial 370 finished with value: 1.5177573926055652 and parameters: {'x': 2.8231578391978975, 'y': -3.7807853992145564}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,334] Trial 371 finished with value: 0.9241220131539462 and parameters: {'x': 3.8110845475688966, 'y': -4.483992374233767}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,340] Trial 372 finished with value: 0.35381058402149956 and parameters: {'x': 2.492702983503984, 'y': -4.689419380714539}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,345] Trial 373 finished with value: 1.3040001632569522 and parameters: {'x': 3.164996114412972, 'y': -3.8700546714616793}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,351] Trial 374 finished with value: 0.178283121415895 and parameters: {'x': 3.4218863185384363, 'y': -5.017177183878043}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,358] Trial 375 finished with value: 0.5057836592122027 and parameters: {'x': 2.8986086335107615, 'y': -5.703920059391439}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,364] Trial 376 finished with value: 4.910463724634087 and parameters: {'x': 3.845662685955677, 'y': -2.951752371851412}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,370] Trial 377 finished with value: 1.1779386211822986 and parameters: {'x': 2.056288901772567, 'y': -4.4639515094092035}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,376] Trial 378 finished with value: 0.1941130739179124 and parameters: {'x': 2.5601363684069356, 'y': -5.025160674070329}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,382] Trial 379 finished with value: 2.3748214629415805 and parameters: {'x': 3.5114786985965525, 'y': -6.453688757548726}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,388] Trial 380 finished with value: 0.9628428495012764 and parameters: {'x': 2.9542448711458817, 'y': -5.980178207105636}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,395] Trial 381 finished with value: 1.5522711901163162 and parameters: {'x': 4.116598642710795, 'y': -4.447298759533934}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,402] Trial 382 finished with value: 1.359222191786705 and parameters: {'x': 3.1660280472389517, 'y': -3.846025615831649}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,409] Trial 383 finished with value: 0.6076252058897562 and parameters: {'x': 2.3108103263152713, 'y': -5.364201591946127}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,415] Trial 384 finished with value: 0.12571892489830222 and parameters: {'x': 2.7107955001780706, 'y': -4.794866672183553}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,422] Trial 385 finished with value: 29.91233029504878 and parameters: {'x': 1.4660887335534458, 'y': -10.249709184489852}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,428] Trial 386 finished with value: 0.9255487929453085 and parameters: {'x': 2.6243623396110984, 'y': -5.885689076958083}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,482] Trial 387 finished with value: 1.4072168762044925 and parameters: {'x': 1.832825228686845, 'y': -5.2119432221482365}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,490] Trial 388 finished with value: 0.9132194806717734 and parameters: {'x': 2.665419695229576, 'y': -4.104860066620026}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,498] Trial 389 finished with value: 1.0315233582973242 and parameters: {'x': 2.1728397089851024, 'y': -5.5893464272102396}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,504] Trial 390 finished with value: 9.783394519736959 and parameters: {'x': 0.4631567260432621, 'y': -3.1702949081566674}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,512] Trial 391 finished with value: 3.134487433340912 and parameters: {'x': 3.6788244707367705, 'y': -6.635140596789724}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,534] Trial 392 finished with value: 299.22257674925436 and parameters: {'x': 2.848749626752565, 'y': 12.297389978659986}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,542] Trial 393 finished with value: 0.2806906314596211 and parameters: {'x': 3.496630353956768, 'y': -4.815476497463341}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,550] Trial 394 finished with value: 1.4127785720803392 and parameters: {'x': 2.2865894754653957, 'y': -4.049303415613793}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,558] Trial 395 finished with value: 9.989406932572424 and parameters: {'x': 5.992671945225842, 'y': -6.0165242549150495}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,564] Trial 396 finished with value: 0.007594628243057377 and parameters: {'x': 3.010026708244311, 'y': -5.086568431687543}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,572] Trial 397 finished with value: 8.374870335064685 and parameters: {'x': 4.657812962796465, 'y': -7.372030041008902}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,579] Trial 398 finished with value: 84.06961371519004 and parameters: {'x': 4.023418636600734, 'y': 4.111653417983386}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,586] Trial 399 finished with value: 0.3408333882031066 and parameters: {'x': 3.233901398329352, 'y': -5.534905154268194}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,593] Trial 400 finished with value: 0.2976363029815303 and parameters: {'x': 3.5365390282941314, 'y': -5.098803715004648}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,600] Trial 401 finished with value: 1.1404582024215697 and parameters: {'x': 3.0445545437204338, 'y': -6.066992546860302}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,607] Trial 402 finished with value: 11.05604385723111 and parameters: {'x': 2.8972662030794565, 'y': -8.323475533865324}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,613] Trial 403 finished with value: 3.169130620725525 and parameters: {'x': 3.925016944277158, 'y': -3.4789890619967014}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,620] Trial 404 finished with value: 16.98102048586916 and parameters: {'x': 7.080743347138013, 'y': -4.426803506066192}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,626] Trial 405 finished with value: 0.18535328117068128 and parameters: {'x': 3.4275685517481955, 'y': -5.050382682805027}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,633] Trial 406 finished with value: 2.9823147826992376 and parameters: {'x': 2.452197214921173, 'y': -6.637750558344926}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,640] Trial 407 finished with value: 0.33470123155470866 and parameters: {'x': 3.0934436496680324, 'y': -5.570937401026966}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,646] Trial 408 finished with value: 1.0080813227906522 and parameters: {'x': 3.649134042192907, 'y': -4.234032430153241}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,654] Trial 409 finished with value: 2.0229808648548553 and parameters: {'x': 4.40721819685022, 'y': -5.206682876185887}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,660] Trial 410 finished with value: 1.410394194732202 and parameters: {'x': 2.718192717193921, 'y': -6.15368056674699}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,666] Trial 411 finished with value: 2.6238958683165556 and parameters: {'x': 1.825510345822897, 'y': -3.8844418793502937}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,672] Trial 412 finished with value: 5.100305151828272 and parameters: {'x': 5.225612803484893, 'y': -4.616655767237345}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,678] Trial 413 finished with value: 0.25655346996924844 and parameters: {'x': 3.2472586111690767, 'y': -5.442059553874801}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,685] Trial 414 finished with value: 0.5176241427645705 and parameters: {'x': 2.339288793143136, 'y': -4.715245994060985}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,691] Trial 415 finished with value: 0.8200629920039978 and parameters: {'x': 2.892665543153768, 'y': -5.899189805534695}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,697] Trial 416 finished with value: 2.8496141170868254 and parameters: {'x': 3.801203488461327, 'y': -3.5141712456799654}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,703] Trial 417 finished with value: 0.6575479154748172 and parameters: {'x': 3.1311431640752794, 'y': -4.19978166354979}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,710] Trial 418 finished with value: 0.20024034165833757 and parameters: {'x': 3.434861139688822, 'y': -5.1055278676316185}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,716] Trial 419 finished with value: 3.631845637508554 and parameters: {'x': 2.5749621812002514, 'y': -6.857737465332092}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,722] Trial 420 finished with value: 8.076852944481383 and parameters: {'x': 2.0439501129300703, 'y': -2.32365518702934}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,728] Trial 421 finished with value: 1.5878805261700937 and parameters: {'x': 4.071344451614429, 'y': -5.6634015316270165}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,734] Trial 422 finished with value: 0.0698927837947675 and parameters: {'x': 2.8088151316039363, 'y': -4.817404463660397}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,740] Trial 423 finished with value: 4.153340032817823 and parameters: {'x': 2.462778151632546, 'y': -3.034107653391346}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,746] Trial 424 finished with value: 0.5379966337600035 and parameters: {'x': 3.5137449587047684, 'y': -4.476489970329661}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,753] Trial 425 finished with value: 1.539013461253541 and parameters: {'x': 2.886189835719221, 'y': -3.76466170311128}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,759] Trial 426 finished with value: 0.11510184993374245 and parameters: {'x': 3.262203277586857, 'y': -4.784706499967017}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,765] Trial 427 finished with value: 1.952874757431847 and parameters: {'x': 1.8970413285319057, 'y': -4.141887579355022}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,773] Trial 428 finished with value: 54.01726312863961 and parameters: {'x': 2.6823123969155547, 'y': -12.342774524352908}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,778] Trial 429 finished with value: 0.19522126119007113 and parameters: {'x': 3.182172136623494, 'y': -4.597464816658094}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,785] Trial 430 finished with value: 2.1578185194074027 and parameters: {'x': 2.2422282889742666, 'y': -6.258411917210154}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,791] Trial 431 finished with value: 0.680350517510741 and parameters: {'x': 3.823527382759432, 'y': -5.046402234387375}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,798] Trial 432 finished with value: 61.478808344485564 and parameters: {'x': -4.738164037449634, 'y': -3.7352369099286835}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,804] Trial 433 finished with value: 0.33482496515337057 and parameters: {'x': 2.9233790731285505, 'y': -5.573545289160961}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,811] Trial 434 finished with value: 20.070740418010065 and parameters: {'x': 3.510845719690927, 'y': -9.450817573062675}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,817] Trial 435 finished with value: 3.5242228214016333 and parameters: {'x': 1.1330326168538045, 'y': -4.803389695921398}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,823] Trial 436 finished with value: 0.9029356960899393 and parameters: {'x': 2.4105064345464036, 'y': -4.254726203077858}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,839] Trial 437 finished with value: 4.729264587508027 and parameters: {'x': 4.340359790743485, 'y': -3.287487162422977}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,847] Trial 438 finished with value: 0.1677416255205825 and parameters: {'x': 3.040282372103832, 'y': -5.407576932637595}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,854] Trial 439 finished with value: 1.6933673270402765 and parameters: {'x': 2.6720706384501973, 'y': -6.2592972885199964}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,861] Trial 440 finished with value: 0.6358379203700043 and parameters: {'x': 3.7800626623928038, 'y': -4.834651389148094}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,868] Trial 441 finished with value: 0.7790654808936546 and parameters: {'x': 3.218768894841616, 'y': -4.144894362348468}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,874] Trial 442 finished with value: 100.04610604243918 and parameters: {'x': -6.966602217802977, 'y': -5.84436145963914}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,881] Trial 443 finished with value: 0.2847058018083422 and parameters: {'x': 3.4915863531954745, 'y': -5.207481708013782}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,887] Trial 444 finished with value: 0.7919211855739672 and parameters: {'x': 2.1687377560122885, 'y': -4.682314200357521}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,894] Trial 445 finished with value: 6.51535286017652 and parameters: {'x': 2.8165077430937027, 'y': -7.545915051966965}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,935] Trial 446 finished with value: 4.221473434698574 and parameters: {'x': 1.4420630755982227, 'y': -3.6604829324401633}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,946] Trial 447 finished with value: 1.9625668733892496 and parameters: {'x': 4.12457915718583, 'y': -5.835397266342461}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,953] Trial 448 finished with value: 2.5572705169589205 and parameters: {'x': 3.2168068183590264, 'y': -6.584381683961272}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,960] Trial 449 finished with value: 0.6168444904100491 and parameters: {'x': 2.549400201737154, 'y': -4.356723766787913}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,967] Trial 450 finished with value: 0.47521567548714283 and parameters: {'x': 3.627076046810403, 'y': -5.286341242233424}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,973] Trial 451 finished with value: 4.146107626635793 and parameters: {'x': 2.896685436058021, 'y': -2.9664234148886175}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,980] Trial 452 finished with value: 1.111102342256132 and parameters: {'x': 1.9516767475984662, 'y': -4.889905945980711}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,988] Trial 453 finished with value: 1.2253209717016962 and parameters: {'x': 3.290616273513154, 'y': -3.9318880427263143}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:35,995] Trial 454 finished with value: 0.6495342535846211 and parameters: {'x': 2.44843285489453, 'y': -5.587629082010772}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,002] Trial 455 finished with value: 2.965328588169233 and parameters: {'x': 4.652138395594253, 'y': -4.51444123942361}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,008] Trial 456 finished with value: 1.949611109931078 and parameters: {'x': 3.8101109587504665, 'y': -6.137247266184218}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,015] Trial 457 finished with value: 0.01402190209064547 and parameters: {'x': 2.9968854046208175, 'y': -5.118373144700432}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,022] Trial 458 finished with value: 3.728488877388717 and parameters: {'x': 2.7088753859197086, 'y': -6.908857075965961}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,028] Trial 459 finished with value: 1.8963820888767653 and parameters: {'x': 1.65164258232065, 'y': -5.279847035120689}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,036] Trial 460 finished with value: 1.1521122458025346 and parameters: {'x': 2.248731766450435, 'y': -4.233378654705042}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,043] Trial 461 finished with value: 2.3319932820965965 and parameters: {'x': 2.9602053829596326, 'y': -3.4734320615998753}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,049] Trial 462 finished with value: 0.4125841138070093 and parameters: {'x': 3.0988476931909044, 'y': -5.634675702511012}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,056] Trial 463 finished with value: 11.244631142609636 and parameters: {'x': -0.35007666912105906, 'y': -4.852971249000793}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,064] Trial 464 finished with value: 156.53401874744412 and parameters: {'x': -9.451744108967738, 'y': -6.219871875334198}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,071] Trial 465 finished with value: 0.3813787713197338 and parameters: {'x': 2.5116983301015137, 'y': -4.621925601906075}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,077] Trial 466 finished with value: 35.23401221440328 and parameters: {'x': -2.9213198938367646, 'y': -5.414708245946763}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,084] Trial 467 finished with value: 1.4209826173902975 and parameters: {'x': 3.4715733076475193, 'y': -3.905193518056878}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,091] Trial 468 finished with value: 6.591017673889295 and parameters: {'x': 2.0599951250095696, 'y': -2.6109816851092327}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,097] Trial 469 finished with value: 0.030706918781456607 and parameters: {'x': 2.8347644003612076, 'y': -5.05834479748414}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,104] Trial 470 finished with value: 0.9674463639783214 and parameters: {'x': 2.714956346278643, 'y': -5.941380092975999}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,110] Trial 471 finished with value: 3.207839750131572 and parameters: {'x': 2.2600658503393873, 'y': -6.631054016364142}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,117] Trial 472 finished with value: 0.024233714281092517 and parameters: {'x': 2.8547540934835394, 'y': -5.056011971232087}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,124] Trial 473 finished with value: 30.001345893853987 and parameters: {'x': 2.5675742083820956, 'y': 0.46025217628248516}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,131] Trial 474 finished with value: 0.23471836781036035 and parameters: {'x': 2.8711836660968064, 'y': -5.46703824247068}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,137] Trial 475 finished with value: 210.10043338907877 and parameters: {'x': 1.8816379330788329, 'y': 9.45163311450822}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,144] Trial 476 finished with value: 14.59812160451905 and parameters: {'x': 2.2817398480951505, 'y': -1.2473710603492019}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,163] Trial 477 finished with value: 0.5854488079717731 and parameters: {'x': 2.8675303982847518, 'y': -4.246408192326126}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,170] Trial 478 finished with value: 1.1907126041304192 and parameters: {'x': 2.5998792037255827, 'y': -6.015192569180422}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,178] Trial 479 finished with value: 1.3267254501387957 and parameters: {'x': 1.8588038527786552, 'y': -5.156194762095131}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,185] Trial 480 finished with value: 145.53628895763256 and parameters: {'x': 3.0167198050999238, 'y': 7.063830627365007}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,192] Trial 481 finished with value: 4.7868949027688625 and parameters: {'x': 2.2561772292977054, 'y': -7.057576873060548}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,199] Trial 482 finished with value: 0.391499911701675 and parameters: {'x': 3.040829600059262, 'y': -4.375634037234031}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,205] Trial 483 finished with value: 1.0650237393764845 and parameters: {'x': 3.725536542124348, 'y': -5.733907668183627}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,212] Trial 484 finished with value: 2.741509319615119 and parameters: {'x': 2.5573497396456286, 'y': -3.404515726613601}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,218] Trial 485 finished with value: 0.12634895452148098 and parameters: {'x': 3.3199335993190604, 'y': -5.154891725241318}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,225] Trial 486 finished with value: 52.489656365626765 and parameters: {'x': 2.8524838945121638, 'y': 2.2434726039551265}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,231] Trial 487 finished with value: 0.9503320719128441 and parameters: {'x': 3.946527476703939, 'y': -4.7667237522650066}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,238] Trial 488 finished with value: 2.8484840000965583 and parameters: {'x': 1.7049173984277077, 'y': -6.082240756579284}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,244] Trial 489 finished with value: 1.6167639968562608 and parameters: {'x': 3.5149300044225025, 'y': -3.8374119012299746}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,251] Trial 490 finished with value: 0.44166569520560367 and parameters: {'x': 2.4173602979629236, 'y': -5.319682143410843}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,258] Trial 491 finished with value: 2.227706589111715 and parameters: {'x': 3.1083015882184615, 'y': -6.4886159192689945}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,265] Trial 492 finished with value: 0.2600920617343812 and parameters: {'x': 2.761560764298591, 'y': -4.549179866673516}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,271] Trial 493 finished with value: 1.1129315457885305 and parameters: {'x': 2.1529394591292457, 'y': -5.628824288564203}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,278] Trial 494 finished with value: 2.081701134908048 and parameters: {'x': 4.132336637935653, 'y': -4.105844044197753}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,284] Trial 495 finished with value: 0.17662994541940968 and parameters: {'x': 3.412009481683126, 'y': -4.917065493173158}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,290] Trial 496 finished with value: 2.8759776786830016 and parameters: {'x': 3.075289931647134, 'y': -3.305801338427051}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,298] Trial 497 finished with value: 0.30364447183693805 and parameters: {'x': 2.5509510210333026, 'y': -5.319373584264423}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,304] Trial 498 finished with value: 0.6674021381488686 and parameters: {'x': 3.6053864146374806, 'y': -4.451447881125918}. Best is trial 235 with value: 0.0019013498280167108.\n",
      "[I 2025-03-28 14:32:36,311] Trial 499 finished with value: 0.9634043752888958 and parameters: {'x': 3.129129867658456, 'y': -5.973000438112648}. Best is trial 235 with value: 0.0019013498280167108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019013498280167108\n",
      "{'x': 2.962631829844541, 'y': -5.022471530594274}\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "# 목적 함수\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    y = trial.suggest_uniform('y', -15, 15)\n",
    "    return (x - 3) ** 2 + (y + 5) ** 2\n",
    "\n",
    "# 스터디 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# 최적화 실행\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# 걀과 확인\n",
    "print(study.best_value)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "x (FloatDistribution): 0.08818353738889756<extra></extra>",
          "y (FloatDistribution): 0.9118164626111025<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.09",
          "0.91"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.08818353738889756,
          0.9118164626111025
         ],
         "y": [
          "x",
          "y"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "# 하이퍼 파라미터 중요도 시각화\n",
    "vis.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          164.28505680253573,
          119.59945123670808,
          94.17242594557987,
          228.8441126600289,
          105.42612093484618,
          49.03809807046863,
          183.516940842614,
          146.84827184732563,
          148.88235643839306,
          436.7011844258296,
          29.356104648586566,
          39.710009628298835,
          47.59955615971471,
          50.22063212561489,
          16.12666122753445,
          11.59024167595262,
          24.39998504144939,
          36.40617255120996,
          11.281536905264772,
          93.55327011349512,
          21.871188260600285,
          3.1738867169471274,
          13.740351970672313,
          18.73904728304297,
          17.871152712433524,
          39.01008370908518,
          57.94925879969561,
          16.325501437317964,
          7.603943318690437,
          125.59102822888588,
          72.29261169316783,
          11.159399699035593,
          23.524825800945415,
          2.2595880805825463,
          1.9686728615222442,
          54.92752445991853,
          6.873848698463408,
          144.7917130152993,
          17.076410546913248,
          27.094382867278057,
          2.1145257401857904,
          1.3060307422269029,
          2.054542147732736,
          1.9392694404275583,
          2.432213296871275,
          25.700767452200065,
          42.615525657973535,
          86.28619268846751,
          80.02699535956246,
          4.64796244770632,
          18.352624999291827,
          0.0014981182179047016,
          1.5703465014945939,
          1.337447611112724,
          334.82168973796433,
          4.657821447370797,
          7.773808267058858,
          148.61062256340563,
          7.665831359787475,
          19.20878211056089,
          1.5148234157217806,
          1.4128452809105272,
          1.1592605303336379,
          1.1268922385172608,
          1.420410399226652,
          28.82103237538745,
          8.891794404082162,
          10.125008587848674,
          21.464243608220087,
          6.6846261979576305,
          19.94160501133329,
          1.1664265357015868,
          17.145290603833274,
          1.0019883269727576,
          8.498073524599997,
          4.445909323880715,
          10.01720207100211,
          12.127593473064413,
          5.943180763215076,
          11.760533291475245,
          17.959683179263475,
          0.649059788181704,
          0.8228977567861855,
          5.091820680088201,
          0.6944092971926392,
          8.818094014354472,
          0.48068916160700914,
          0.9581962157642537,
          27.48767384500104,
          6.8322937096751915,
          18.460668024495163,
          1.381053634246901,
          0.3819835489625593,
          4.050288155287158,
          1.0785801490920015,
          23.785434773201054,
          1.9299747613784715,
          15.177181223480591,
          13.766445571245853,
          6.311009124822941,
          179.99331126409066,
          0.5770974268956535,
          0.5899954844213037,
          3.4821782160998516,
          0.5551029015090464,
          3.2477089209932113,
          1.620857337637662,
          10.740058597761072,
          9.554704670228999,
          6.289045159490779,
          0.716189842804392,
          0.651914685902163,
          3.6334798070798158,
          0.6732584821613098,
          0.7308804859379467,
          1.2302625178595383,
          14.305547142322643,
          92.86464237836877,
          6.520272764143774,
          1.4248529416940063,
          9.467019441854625,
          3.211252641016709,
          0.4463200051216606,
          0.4173165686287143,
          2.5168205229226603,
          6.529767758240547,
          3.6769468775791703,
          3.0388480094595676,
          8.116857305066912,
          0.585088314659345,
          0.6053640864165317,
          0.7033891920480162,
          0.10256325215472557,
          3.3263902797716547,
          0.13987004209669712,
          2.36985419009738,
          5.323415273742507,
          5.251351183591381,
          4.034786135163605,
          7.7708613114868195,
          15.052230987668723,
          0.9438610917744994,
          0.015510044913643564,
          2.1641807240294484,
          0.010915753663248174,
          0.00989650801660393,
          0.005547663000726553,
          1.2055937265357752,
          1.3959851746773342,
          6.248231790664373,
          1.3432602607532285,
          0.6208895352103418,
          3.5682949957671464,
          0.06656718075715917,
          0.0027301495561296296,
          1.1400973558703402,
          0.10545931918361315,
          0.07285165307131865,
          3.119106744565096,
          1.8049174342018273,
          0.7921815514546393,
          0.13112213044164592,
          0.09697905680683147,
          1.7132920150327844,
          2.2819851416302304,
          1.1752531738905374,
          0.1402733861268368,
          0.590263415138434,
          4.865375822254544,
          0.18041282667390154,
          6.040489902109562,
          0.04160668201888604,
          0.06650312874977159,
          0.15803732712742172,
          0.11139455705065743,
          1.072816986260609,
          1.3035536796372766,
          2.0722014219650355,
          2.208599457911784,
          0.05502430017787979,
          101.17402826047321,
          0.06020395887181579,
          0.04893612277629165,
          1.320263208121764,
          0.21272346532145442,
          2.933899303766766,
          2.292011420325244,
          0.6012407785409817,
          39.05057996367379,
          1.140566145204144,
          2.1866375888866836,
          0.16240856813023474,
          0.00019076152789880313,
          0.21655058660148732,
          1.2826704007333007,
          4.030344489788186,
          1.1218951357398665,
          50.932763115264756,
          0.8575357629293765,
          326.06617667838987,
          0.9479034971087565,
          0.004516284228204053,
          0.2288190612858577,
          0.006586356565579018,
          0.10482334331214589,
          0.8609778005185666,
          1.4496413055652944,
          0.1386192962161196,
          1.825485134338875,
          2.9129040652226945,
          0.00017759518833837263,
          0.05733514086029445,
          0.3537587367785162,
          1.0793236871727558,
          0.01677926108797541,
          2.3004244060513215,
          0.09350729296337483,
          20.430160485807228,
          1.0198158428715123,
          40.4215166198169,
          0.46826827989168984,
          0.08434054831714025,
          0.616642023768878,
          0.044966488945443854,
          0.07122772277852776,
          1.5572087995573665,
          1.3670557483386043,
          0.9420861672338849,
          1.1881727862016163,
          2.3758522412534417,
          1.0771797053452161,
          0.04434336088302947,
          0.11010277050248887,
          0.026162899168397747,
          0.4833903140178423,
          1.548582656136663,
          1.5951671510674281,
          74.06376679751877,
          2.660333635996963,
          0.4819303575708203,
          0.7331758775436782,
          0.11637777156724072,
          0.015752801760784394,
          0.41256836657845664,
          0.553626375309392,
          0.687471952625818,
          0.002498537186282973,
          1.818174455415853,
          1.5748555281477643,
          0.30682887420937627,
          0.2671180477874808,
          2.731547482869691,
          63.08921502363013,
          1.1388389956118776,
          0.010684161943203001,
          1.2042088435413953,
          0.9653966763327895,
          3.973458212008282,
          4.962777145523781,
          0.5678768603432638,
          1.1009747418006237,
          0.5570726806600906,
          2.211468545694968,
          1.8863001007834928,
          2.3634765056068385,
          0.5051421898989593,
          0.21122790631156263,
          1.3568805144567289,
          0.0422271361193333,
          2.4411569018248187,
          1.0900938484864424,
          0.26246752693119874,
          50.15174822195412,
          1.9310403153835427,
          2.305110389191301,
          1.4125724797634387,
          156.9585328910087,
          1.0097853999864979,
          1.4499266115212126,
          166.8267477158563,
          4.755321742597966,
          1.305960676680543,
          3.6013229359254915,
          0.32477800458380124,
          17.779589332913545,
          1.0936680947873487,
          0.038389895544280364,
          0.356819790587347,
          1.4268943749606566,
          0.649568896443988,
          3.445807700130268,
          69.67916566219944,
          0.06292941030838281,
          87.37217222775142,
          2.0924235574261743,
          2.6318535525108055,
          0.34932990518482976,
          3.3720408177868144,
          34.73200659436709,
          0.14289384761123253,
          1.1448681758638362,
          0.34321752832602054,
          4.654656535603223,
          0.43171710104611355,
          1.8169770751737937,
          136.15217055989444,
          0.044379595883278306,
          2.0543897301246434,
          0.5741558221323667,
          1.7529373787478804,
          36.32759539462792,
          0.11709807043186107,
          0.3666559870533085,
          8.30524839826314,
          2.3602839240765103,
          0.35732194876696666,
          3.006910669760687,
          1.330467827409077,
          26.95624094504728,
          3.703314621602263,
          0.36647983380050164,
          0.16409690024772838,
          2.08339697502141,
          6.391826863944768,
          1.5638600124582966,
          0.09630829370244826,
          269.5938253931346,
          1.7392465003934914,
          3.50258829340626,
          0.4991597673132403,
          0.09683399102671623,
          2.2797969977015304,
          1.6420515043337802,
          0.0902935634759785,
          1.1034373740439496,
          0.4434141233183683,
          1.4190772517598322,
          3.8207074103545713,
          0.23246496716299497,
          0.8072099192735429,
          0.346851324879391,
          2.771498077212377,
          0.3896869936416267,
          4.916657273984816,
          1.5773185632969082,
          14.426056229392513,
          0.4434625872589898,
          1.0269610555525361,
          2.375640656845579,
          1.011640139153926,
          83.52715509585896,
          4.589461507392668,
          4.603777300569214,
          1.0605192938670756,
          2.299450472925164,
          2.931689631334272,
          0.6116140158305066,
          2.041548704009624,
          0.03797349421728105,
          0.37871507530532966,
          3.491955215965043,
          0.15840204820746429,
          2.5378415824481597,
          0.668670365173196,
          1.3353977039752527,
          4.097101490411872,
          0.6697225242814422,
          0.20559951580947822,
          1.3071034476983403,
          1.5353916212922378,
          2.622505876764747,
          0.10439996790164945,
          1.0170214552919092,
          1.1413348701277704,
          7.9885654075445895,
          0.008047424795502313,
          1.2939266882345515,
          0.06778191807164173,
          1.6226946057222753,
          0.6996404160215238,
          6.13089223938613,
          27.120261602175717,
          3.4739357184644555,
          28.246620257645326,
          0.3772384941825203,
          2.7059526294967857,
          0.24255122604500157,
          0.8645899825729879,
          1.0378542239438875,
          0.5927935359087976,
          0.9506157323289507,
          99.4206026484607,
          1.814086407415609,
          2.074877100010908,
          20.772496736834537,
          11.34286467163818,
          3.8504329867414055,
          16.81152411363955,
          0.058264994540583696,
          0.9860475985309808,
          2.151020003819059,
          3.3537746653892553,
          9.489650516771622,
          0.4346938907556397,
          0.9617022046013122,
          4.17910272707125,
          0.401171866792883,
          378.6175190319484,
          1.6369491367640367,
          39.49768907717726,
          0.19155539001449481,
          0.41334750919299584,
          0.9688363673698908,
          0.03911330300493433,
          2.6843009766772754,
          0.2723986272694625,
          0.6274942918366103,
          1.4330183934726337,
          2.535264858139054,
          0.46971005966714013,
          1.2015840214072286,
          2.2697073595324597,
          3.4213560396439435,
          0.4272574931410744,
          0.3440208315865132,
          0.27916172631167413,
          3.29878003249545,
          1.8608919558972163,
          2.0002201183983765,
          4.977521127009486,
          1.3506776534542506,
          0.0381584727921063,
          1.3136603534816924,
          37.137968690088876,
          0.24417118583705943,
          0.5719039027351052,
          25.548485396640093,
          4.607776750887231,
          0.4302833210968208,
          2.0750399688079297,
          0.6132868666602938,
          0.11031474543617104,
          1.4149411017053632,
          0.7325862219601511,
          80.90312939092631,
          1.9852636953922491,
          0.9350589530359719,
          1.6248298428648429,
          0.19538656595293652,
          2.4217525472890884,
          4.0341199695816545,
          44.514260323867134,
          0.18988707127029225,
          2.361664573795072,
          8.244446148451775,
          3.362428208543353,
          123.15208321971927,
          0.22302885366469444,
          0.9824604684274373,
          0.9310023644642682,
          1.1208144757514458,
          1.6319527018591715,
          0.09771939292411695,
          1.9287979135429454,
          15.666718358510057,
          0.6489603458277204,
          215.8973901854315,
          3.6235352482027365,
          10.365224800548546,
          4.450227263539823,
          0.8527173206354426,
          1.7204815367435353,
          3.7278244198327855,
          1.8997625294319764,
          1.5933358212219255,
          3.5454023674288617,
          0.13453851059416072,
          0.5532991796764157,
          1.1218653649500567,
          0.5244560046073656,
          57.498309220183486,
          55.49431536586215,
          0.295035781396413,
          156.75160788423022,
          0.642573785838655,
          7.840514254949299,
          5.861926953032486,
          1.101936882300471,
          1.3745776974489163,
          2.9437580002474526,
          0.8634545025467345,
          3.099684316372765,
          0.6210229596443486,
          3.811658260459904,
          3.293790966575374,
          28.319963497118028,
          0.1107224361303222,
          0.6833331997476936,
          10.781726253739754,
          2.5386904331446063
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          164.28505680253573,
          119.59945123670808,
          94.17242594557987,
          94.17242594557987,
          94.17242594557987,
          49.03809807046863,
          49.03809807046863,
          49.03809807046863,
          49.03809807046863,
          49.03809807046863,
          29.356104648586566,
          29.356104648586566,
          29.356104648586566,
          29.356104648586566,
          16.12666122753445,
          11.59024167595262,
          11.59024167595262,
          11.59024167595262,
          11.281536905264772,
          11.281536905264772,
          11.281536905264772,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          3.1738867169471274,
          2.2595880805825463,
          1.9686728615222442,
          1.9686728615222442,
          1.9686728615222442,
          1.9686728615222442,
          1.9686728615222442,
          1.9686728615222442,
          1.9686728615222442,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          1.3060307422269029,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.0014981182179047016,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00019076152789880313,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263,
          0.00017759518833837263
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최적화 히스토리 시각화\n",
    "vis.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optuna를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:22:06,629] A new study created in memory with name: no-name-8383034c-5f14-4766-8358-39d88069e862\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:07,454] Trial 551 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.1021954428835251, 'colsample_bytree': 0.733950853365068}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:08,130] Trial 552 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.12683619495581838, 'colsample_bytree': 0.9107598787552083}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:08,520] Trial 553 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08209303824032708, 'colsample_bytree': 0.5010028693569684}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:09,604] Trial 554 finished with value: 0.960093896713615 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.07444417924661434, 'colsample_bytree': 0.991588360533862}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:10,031] Trial 555 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.04987885404816709, 'colsample_bytree': 0.5844389520848873}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:10,964] Trial 556 finished with value: 0.9507042253521126 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.011493747933587567, 'colsample_bytree': 0.8199700065004732}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:11,647] Trial 557 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.19395131052841444, 'colsample_bytree': 0.7740530979546558}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:12,591] Trial 558 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.06192314865671828, 'colsample_bytree': 0.7954198991523058}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:13,436] Trial 559 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.11672142179295976, 'colsample_bytree': 0.843183194829102}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:14,469] Trial 560 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0349545941932127, 'colsample_bytree': 0.6987520569111236}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:14,768] Trial 561 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.16160433959148934, 'colsample_bytree': 0.5491326901638415}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:15,470] Trial 562 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.13821332091908398, 'colsample_bytree': 0.7536827204322073}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:15,907] Trial 563 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.17920302056415238, 'colsample_bytree': 0.9034878761091903}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:16,642] Trial 564 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1693475753416879, 'colsample_bytree': 0.9472714377740787}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:16,978] Trial 565 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.09549935619128957, 'colsample_bytree': 0.8685579570975162}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:17,506] Trial 566 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.07703319769565736, 'colsample_bytree': 0.6444941576399834}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:18,303] Trial 567 finished with value: 0.9624413145539905 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.08662868097216747, 'colsample_bytree': 0.6711225704534776}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:18,895] Trial 568 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.12272273281868616, 'colsample_bytree': 0.9816857571721973}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:19,636] Trial 569 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1308474208945256, 'colsample_bytree': 0.6267420985264112}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:20,249] Trial 570 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.15327877495994094, 'colsample_bytree': 0.5254749135782968}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:20,532] Trial 571 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.14454723762626023, 'colsample_bytree': 0.719917786112576}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:21,199] Trial 572 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.04368190398356238, 'colsample_bytree': 0.9251833830079907}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:21,811] Trial 573 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.10855583402967418, 'colsample_bytree': 0.6982702618746236}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:23,380] Trial 574 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.018714286037173913, 'colsample_bytree': 0.5896706689745803}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:23,959] Trial 575 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.06228822740259348, 'colsample_bytree': 0.7657429174941215}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:24,555] Trial 576 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.11416757321384197, 'colsample_bytree': 0.8142146875450416}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:24,918] Trial 577 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.07135039098343807, 'colsample_bytree': 0.5565520872962034}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:26,122] Trial 578 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.02812493251235046, 'colsample_bytree': 0.7932025090349462}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:27,049] Trial 579 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.053708501067139695, 'colsample_bytree': 0.9654859940212512}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:27,542] Trial 580 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.17496798182518547, 'colsample_bytree': 0.8651737544273705}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:28,368] Trial 581 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.10098369575676432, 'colsample_bytree': 0.7406068987004104}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:28,624] Trial 582 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.1954529258931858, 'colsample_bytree': 0.8939797476547692}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:29,044] Trial 583 finished with value: 0.9624413145539905 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.16283999373485575, 'colsample_bytree': 0.6544594814963163}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:29,699] Trial 584 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.18669966221238682, 'colsample_bytree': 0.9366390915390742}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:30,324] Trial 585 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.14390747219798136, 'colsample_bytree': 0.6136355677750953}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:30,814] Trial 586 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.09391223209235673, 'colsample_bytree': 0.8807055246946881}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:31,231] Trial 587 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.04763268082376437, 'colsample_bytree': 0.8498377923854827}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:31,859] Trial 588 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1053090918363831, 'colsample_bytree': 0.5191287219434697}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:33,008] Trial 589 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.01671788266108655, 'colsample_bytree': 0.7243420324258097}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:34,237] Trial 590 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.03439189380034868, 'colsample_bytree': 0.950282191358783}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:34,746] Trial 591 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.08319849094136306, 'colsample_bytree': 0.5762209664276801}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:35,402] Trial 592 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.13567470586000513, 'colsample_bytree': 0.6050289634993666}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:35,710] Trial 593 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.12047478068648917, 'colsample_bytree': 0.9999879287938602}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:36,571] Trial 594 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04068986342211536, 'colsample_bytree': 0.8299937882247735}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:37,128] Trial 595 finished with value: 0.9530516431924881 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.19226464651782815, 'colsample_bytree': 0.7454603341630406}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:37,708] Trial 596 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06034633869419132, 'colsample_bytree': 0.7895087991659226}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:39,119] Trial 597 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.024814904475163532, 'colsample_bytree': 0.9753470675551608}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:39,419] Trial 598 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.12829967561718922, 'colsample_bytree': 0.5371023801321421}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:40,036] Trial 599 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.158729564271811, 'colsample_bytree': 0.5123209769850574}. Best is trial 210 with value: 0.00017759518833837263.\n",
      "/var/folders/3n/_m4swqjn32qg1gw1xlfsyvx00000gn/T/ipykernel_21478/209299789.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[14:22:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[14:22:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"max_deepth\" } are not used.\n",
      "\n",
      "[I 2025-03-28 14:22:40,471] Trial 600 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.18143539186716312, 'colsample_bytree': 0.6780010007365133}. Best is trial 210 with value: 0.00017759518833837263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 3.0023325422423244, 'y': -5.013120763507744}\n",
      "0.00017759518833837263\n"
     ]
    }
   ],
   "source": [
    "# 1. 목적 함수\n",
    "def xgb_optuna_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "        'max_deepth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)  # Fixed typo here\n",
    "    }\n",
    "    xgb_clf = XGBClassifier(**params)\n",
    "    return cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "\n",
    "# 2. study 객체 -> 최적화\n",
    "optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_optuna_objective, n_trials=50)\n",
    "\n",
    "# 3. 결과 출력\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"cilsample_bytree\" } are not used.\n",
      "\n",
      "[14:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"cilsample_bytree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt 최적 파라미터 적용: 0.958041958041958\n",
      "Optuna 최적 파라미터 적용: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_hpopt = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.17,\n",
    "    cilsample_bytree=0.75\n",
    ")\n",
    "\n",
    "xgb_optuna = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.18,\n",
    "    cilsample_bytree=0.67\n",
    ")\n",
    "\n",
    "xgb_hpopt.fit(X_train, y_train)\n",
    "xgb_optuna.fit(X_train, y_train)\n",
    "\n",
    "hpopt_pred = xgb_hpopt.predict(X_test)\n",
    "optuna_pred = xgb_optuna.predict(X_test)\n",
    "\n",
    "print(f'HyperOpt 최적 파라미터 적용: {accuracy_score(y_test, hpopt_pred)}')\n",
    "print(f'Optuna 최적 파라미터 적용: {accuracy_score(y_test, hpopt_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
