{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정홧도  (Accuracy)\n",
    "- 전체 샘플 중에서 올바르게 예측한 샘플의 비율\n",
    "- 데이터가 불균형한 경우 정확도는 비현실적인 성능을 낼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "# 성별로만 판단\n",
    "class MyTitanicClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            sex = X['Sex'].iloc[i]\n",
    "            if sex == 0:        # 여성\n",
    "                pred[i] = 1     # 생전\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 -> 함수\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fillna(df):\n",
    "    \"\"\"\n",
    "    결측치 처리 함수\n",
    "    - Age : 평균치로 대체\n",
    "    - Cabin : 'N' 기본값으로 대체\n",
    "    - Embarked : 'N' 기본값으로 대체\n",
    "    \"\"\"\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Cabin'] = df['Cabin'].fillna('N')\n",
    "    df['Embarked'] = df['Embarked'].fillna('N')\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_feature(df):\n",
    "    \"\"\"\n",
    "    모델 훈련과 관련 없는 속성 제거\n",
    "    - PassengerId, Name, Ticket\n",
    "    \"\"\"\n",
    "    return df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "\n",
    "def encode_feature(df):\n",
    "    \"\"\"\n",
    "    범주형 데이터를 숫자로 인코딩\n",
    "    - Sex, Cabin, Embarked\n",
    "    \"\"\"\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "\n",
    "    categories = ['Sex', 'Cabin', 'Embarked']\n",
    "    for cate_item in categories:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[cate_item] = label_encoder.fit_transform(df[cate_item])\n",
    "\n",
    "    return df\n",
    "\n",
    "def scailing_feature(train_data, test_data):\n",
    "    \"\"\"\n",
    "    특성 스케일링\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = drop_feature(df)\n",
    "    df = fillna(df)\n",
    "    df = encode_feature(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# 입력/라벨 데이터 분리\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# 전처리\n",
    "X = preprocess_data(X)\n",
    "\n",
    "# 훈련/테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 정확도: 0.7889221556886228\n",
      "평가 데이터 정확도: 0.7802690582959642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 훈련\n",
    "my_classifier = MyTitanicClassifier()\n",
    "my_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred_train = my_classifier.predict(X_train)\n",
    "pred_test = my_classifier.predict(X_test)\n",
    "\n",
    "# 평가 (accurancy_score)\n",
    "print(\"훈련 데이터 정확도:\", accuracy_score(y_train, pred_train))\n",
    "print(\"평가 데이터 정확도:\", accuracy_score(y_test, pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정밀도 (Precision)\n",
    "    - 양성이라고 예측한 것(TP + FP)중에 실제 양성(TP)알 확률\n",
    "    - 정밀도가 중요한 지표인 경유: 음성인 데이터를 양성으로 예측하면 안되는 경우(스팸메일 분류 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://d.pr/i/rtYBJv+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,  24],\n",
       "       [ 25,  59]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, pred_test)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7108433734939759, 0.7108433734939759)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_score = 59 / (24+59)\n",
    "p_score, precision_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 재현율\n",
    "    - 실제 양성 (TP + FN)중에 양성으로 예측(TP)한 확률\n",
    "    - 재현율이 중요한 지표인 경우  : 양성인 데이터를 음성으로 예측하면 안되는 경우(암 진단, 보험/ 금융사기 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023809523809523"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 혼동행렬:\n",
      " [[410   0]\n",
      " [258   0]]\n",
      "훈련 데이터 장확도:\n",
      " 0.6137724550898204\n",
      "훈련 데이터 정밀도:\n",
      " 0.0\n",
      "훈련 데이터 재현율:\n",
      " 0.0\n",
      "데이터 혼동행렬:\n",
      " [[139   0]\n",
      " [ 84   0]]\n",
      "데이터 장확도:\n",
      " 0.6233183856502242\n",
      "데이터 정밀도:\n",
      " 0.0\n",
      "데이터 재현율:\n",
      " 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 잘못 학습된 모델 만들어보기(2)\n",
    "class MyDeathClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros((X.shape[0], 1))    # 전부 사망\n",
    "    \n",
    "my_classifier = MyDeathClassifier()\n",
    "my_classifier.fit(X_train, y_train)\n",
    "\n",
    "pred_train = my_classifier.predict(X_train)\n",
    "pred_test = my_classifier.predict(X_test)\n",
    "\n",
    "print(\"훈련 데이터 혼동행렬:\\n\", confusion_matrix(y_train, pred_train))\n",
    "print(\"훈련 데이터 장확도:\\n\", accuracy_score(y_train, pred_train))\n",
    "print(\"훈련 데이터 정밀도:\\n\", precision_score(y_train, pred_train))\n",
    "print(\"훈련 데이터 재현율:\\n\", recall_score(y_train, pred_train))\n",
    "\n",
    "print(\"데이터 혼동행렬:\\n\", confusion_matrix(y_test, pred_test))\n",
    "print(\"데이터 장확도:\\n\", accuracy_score(y_test, pred_test))\n",
    "print(\"데이터 정밀도:\\n\", precision_score(y_test, pred_test))\n",
    "print(\"데이터 재현율:\\n\", recall_score(y_test, pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차행렬, 정확도, 정밀도, 재현율 계산 및 출력 함수\n",
    "def evaluate_binary_classification(y_true, y_pred):\n",
    "    print(\"혼동행렬:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(f\"정확도: {accuracy_score(y_true, y_pred)} 정밀도: {precision_score(y_true, y_pred)} 재현율: {recall_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬:\n",
      " [[350  60]\n",
      " [ 78 180]]\n",
      "정확도: 0.7934131736526946 정밀도: 0.75 재현율: 0.6976744186046512\n",
      "혼동행렬:\n",
      " [[117  22]\n",
      " [ 23  61]]\n",
      "정확도: 0.7982062780269058 정밀도: 0.7349397590361446 재현율: 0.7261904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pystudy_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# 입력/라벨 데이터 분리\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# 전처리\n",
    "X = preprocess_data(X)\n",
    "\n",
    "# 훈련/테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# 모델 훈련\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평기\n",
    "pred_train = lr_clf.predict(X_train)\n",
    "pred_test = lr_clf.predict(X_test)\n",
    "evaluate_binary_classification(y_train, pred_train)\n",
    "evaluate_binary_classification(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정밀도-재현율의 trade-off\n",
    "    - 분류 결정 임계치(threshold)를 낮추면? Positive로 예측할 확률이 높아진다!\n",
    "        - 정밀도는 낮아지고, 재현율이 높아진다\n",
    "    - 분류 결정 임계치(threshold)를 높히면? Positive로 예측할 확률이 낮아진다!\n",
    "        - 정밀도는 높아지고, 재현율이 낮아진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83388279 0.16611721]\n",
      " [0.88893545 0.11106455]\n",
      " [0.91997745 0.08002255]\n",
      " [0.05652739 0.94347261]\n",
      " [0.29788096 0.70211904]\n",
      " [0.50951837 0.49048163]\n",
      " [0.09503411 0.90496589]]\n",
      "[0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "print(pred_proba[:7])\n",
    "\n",
    "pred = lr_clf.predict(X_test)\n",
    "print(pred[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "temp_X = [[1, -1, 2], [2, 0, 0], [0, 1.1, 1.2]]\n",
    "# Binarizer(threshoid)\n",
    "# - threshold보다 크면 1 반환\n",
    "# - threshold보다 작거나 같으면 0 반환\n",
    "binarizer = Binarizer(threshold=0)\n",
    "adj_X = binarizer.fit_transform(temp_X)\n",
    "adj_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬:\n",
      " [[117  22]\n",
      " [ 23  61]]\n",
      "정확도: 0.7982062780269058 정밀도: 0.7349397590361446 재현율: 0.7261904761904762\n",
      "혼동행렬:\n",
      " [[124  15]\n",
      " [ 29  55]]\n",
      "정확도: 0.8026905829596412 정밀도: 0.7857142857142857 재현율: 0.6547619047619048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# 1(생존)일 확률만 가져오고 + 배치 차원 추가\n",
    "predict_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.5)\n",
    "custom_pred = binarizer.fit_transform(predict_proba_1)\n",
    "evaluate_binary_classification(y_test, custom_pred)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.6)\n",
    "custom_pred = binarizer.fit_transform(predict_proba_1)\n",
    "evaluate_binary_classification(y_test, custom_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
